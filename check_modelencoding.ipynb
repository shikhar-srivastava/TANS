{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a standard resnet from pytorch\n",
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "def resnet_model():\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 is a convolutional layer\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n"
     ]
    }
   ],
   "source": [
    "if isinstance(model.conv1, torch.nn.Conv2d):\n",
    "    print('Conv1 is a convolutional layer')\n",
    "    print(model.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def get_module_by_name(module: Union[torch.Tensor, nn.Module],\n",
    "                       access_string: str):\n",
    "    \"\"\"Retrieve a module nested in another by its access string.\n",
    "\n",
    "    Works even when there is a Sequential in the module.\n",
    "    \"\"\"\n",
    "    names = access_string.split(sep='.')\n",
    "    return reduce(getattr, names, module)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchvision.models import resnet34\n",
    "    \n",
    "    model = resnet34()\n",
    "    get_module_by_name(model, 'layer1.0.relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_module_by_name(model, 'layer1.0.conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 is a convolutional layer\n",
      "64 (3, 3) 64 (1, 1) (1, 1) (1, 1) 1 None zeros\n"
     ]
    }
   ],
   "source": [
    "if isinstance(x, torch.nn.Conv2d):\n",
    "    print('Conv1 is a convolutional layer')\n",
    "    print(x.in_channels,\\\n",
    "    x.kernel_size,\\\n",
    "    x.out_channels,\\\n",
    "    x.stride,\\\n",
    "    x.padding,\\\n",
    "    x.dilation,\\\n",
    "    x.groups,\\\n",
    "    x.bias,\\\n",
    "    x.padding_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1 conv1\n",
      "2 bn1\n",
      "3 relu\n",
      "4 maxpool\n",
      "5 layer1\n",
      "6 layer1.0\n",
      "7 layer1.0.conv1\n",
      "8 layer1.0.bn1\n",
      "9 layer1.0.relu\n",
      "10 layer1.0.conv2\n",
      "11 layer1.0.bn2\n",
      "12 layer1.1\n",
      "13 layer1.1.conv1\n",
      "14 layer1.1.bn1\n",
      "15 layer1.1.relu\n",
      "16 layer1.1.conv2\n",
      "17 layer1.1.bn2\n",
      "18 layer1.2\n",
      "19 layer1.2.conv1\n",
      "20 layer1.2.bn1\n",
      "21 layer1.2.relu\n",
      "22 layer1.2.conv2\n",
      "23 layer1.2.bn2\n",
      "24 layer2\n",
      "25 layer2.0\n",
      "26 layer2.0.conv1\n",
      "27 layer2.0.bn1\n",
      "28 layer2.0.relu\n",
      "29 layer2.0.conv2\n",
      "30 layer2.0.bn2\n",
      "31 layer2.0.downsample\n",
      "32 layer2.0.downsample.0\n",
      "33 layer2.0.downsample.1\n",
      "34 layer2.1\n",
      "35 layer2.1.conv1\n",
      "36 layer2.1.bn1\n",
      "37 layer2.1.relu\n",
      "38 layer2.1.conv2\n",
      "39 layer2.1.bn2\n",
      "40 layer2.2\n",
      "41 layer2.2.conv1\n",
      "42 layer2.2.bn1\n",
      "43 layer2.2.relu\n",
      "44 layer2.2.conv2\n",
      "45 layer2.2.bn2\n",
      "46 layer2.3\n",
      "47 layer2.3.conv1\n",
      "48 layer2.3.bn1\n",
      "49 layer2.3.relu\n",
      "50 layer2.3.conv2\n",
      "51 layer2.3.bn2\n",
      "52 layer3\n",
      "53 layer3.0\n",
      "54 layer3.0.conv1\n",
      "55 layer3.0.bn1\n",
      "56 layer3.0.relu\n",
      "57 layer3.0.conv2\n",
      "58 layer3.0.bn2\n",
      "59 layer3.0.downsample\n",
      "60 layer3.0.downsample.0\n",
      "61 layer3.0.downsample.1\n",
      "62 layer3.1\n",
      "63 layer3.1.conv1\n",
      "64 layer3.1.bn1\n",
      "65 layer3.1.relu\n",
      "66 layer3.1.conv2\n",
      "67 layer3.1.bn2\n",
      "68 layer3.2\n",
      "69 layer3.2.conv1\n",
      "70 layer3.2.bn1\n",
      "71 layer3.2.relu\n",
      "72 layer3.2.conv2\n",
      "73 layer3.2.bn2\n",
      "74 layer3.3\n",
      "75 layer3.3.conv1\n",
      "76 layer3.3.bn1\n",
      "77 layer3.3.relu\n",
      "78 layer3.3.conv2\n",
      "79 layer3.3.bn2\n",
      "80 layer3.4\n",
      "81 layer3.4.conv1\n",
      "82 layer3.4.bn1\n",
      "83 layer3.4.relu\n",
      "84 layer3.4.conv2\n",
      "85 layer3.4.bn2\n",
      "86 layer3.5\n",
      "87 layer3.5.conv1\n",
      "88 layer3.5.bn1\n",
      "89 layer3.5.relu\n",
      "90 layer3.5.conv2\n",
      "91 layer3.5.bn2\n",
      "92 layer4\n",
      "93 layer4.0\n",
      "94 layer4.0.conv1\n",
      "95 layer4.0.bn1\n",
      "96 layer4.0.relu\n",
      "97 layer4.0.conv2\n",
      "98 layer4.0.bn2\n",
      "99 layer4.0.downsample\n",
      "100 layer4.0.downsample.0\n",
      "101 layer4.0.downsample.1\n",
      "102 layer4.1\n",
      "103 layer4.1.conv1\n",
      "104 layer4.1.bn1\n",
      "105 layer4.1.relu\n",
      "106 layer4.1.conv2\n",
      "107 layer4.1.bn2\n",
      "108 layer4.2\n",
      "109 layer4.2.conv1\n",
      "110 layer4.2.bn1\n",
      "111 layer4.2.relu\n",
      "112 layer4.2.conv2\n",
      "113 layer4.2.bn2\n",
      "114 avgpool\n",
      "115 fc\n"
     ]
    }
   ],
   "source": [
    "for ix, name in enumerate(model.named_modules()):\n",
    "    print(ix, name[0])\n",
    "    #if name[0] is not '':\n",
    "    #    print(get_module_by_name(model, name[0]))\n",
    "    #print(get_module_by_name(model, 'layer1.0.conv1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook( m, i, o):\n",
    "    print( m._get_name() )\n",
    "\n",
    "for ( mo ) in model.modules():\n",
    "    mo.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the configurations of each layer\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "bn1.weight torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "bn1.bias torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.downsample.1.weight torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.0.downsample.1.bias torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.downsample.1.weight torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.0.downsample.1.bias torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.downsample.1.weight torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.0.downsample.1.bias torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "fc.weight torch.Size([1000, 512])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "fc.bias torch.Size([1000])\n",
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "# Iterate model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once for All: Train One Network and Specialize it for Efficient Deployment\n",
    "# Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, Song Han\n",
    "# International Conference on Learning Representations (ICLR), 2020.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from ofa.utils import get_same_padding, min_divisible_value, SEModule, ShuffleLayer\n",
    "from ofa.utils import MyNetwork, MyModule\n",
    "from ofa.utils import build_activation, make_divisible\n",
    "\n",
    "__all__ = [\n",
    "\t'set_layer_from_config',\n",
    "\t'ConvLayer', 'IdentityLayer', 'LinearLayer', 'MultiHeadLinearLayer', 'ZeroLayer', 'MBConvLayer',\n",
    "\t'ResidualBlock', 'ResNetBottleneckBlock',\n",
    "]\n",
    "\n",
    "\n",
    "def set_layer_from_config(layer_config):\n",
    "\tif layer_config is None:\n",
    "\t\treturn None\n",
    "\n",
    "\tname2layer = {\n",
    "\t\tConvLayer.__name__: ConvLayer,\n",
    "\t\tIdentityLayer.__name__: IdentityLayer,\n",
    "\t\tLinearLayer.__name__: LinearLayer,\n",
    "\t\tMultiHeadLinearLayer.__name__: MultiHeadLinearLayer,\n",
    "\t\tZeroLayer.__name__: ZeroLayer,\n",
    "\t\tMBConvLayer.__name__: MBConvLayer,\n",
    "\t\t'MBInvertedConvLayer': MBConvLayer,\n",
    "\t\t##########################################################\n",
    "\t\tResidualBlock.__name__: ResidualBlock,\n",
    "\t\tResNetBottleneckBlock.__name__: ResNetBottleneckBlock,\n",
    "\t}\n",
    "\n",
    "\tlayer_name = layer_config.pop('name')\n",
    "\tlayer = name2layer[layer_name]\n",
    "\treturn layer.build_from_config(layer_config)\n",
    "\n",
    "\n",
    "class My2DLayer(MyModule):\n",
    "\n",
    "\tdef __init__(self, in_channels, out_channels,\n",
    "\t             use_bn=True, act_func='relu', dropout_rate=0, ops_order='weight_bn_act'):\n",
    "\t\tsuper(My2DLayer, self).__init__()\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.out_channels = out_channels\n",
    "\n",
    "\t\tself.use_bn = use_bn\n",
    "\t\tself.act_func = act_func\n",
    "\t\tself.dropout_rate = dropout_rate\n",
    "\t\tself.ops_order = ops_order\n",
    "\n",
    "\t\t\"\"\" modules \"\"\"\n",
    "\t\tmodules = {}\n",
    "\t\t# batch norm\n",
    "\t\tif self.use_bn:\n",
    "\t\t\tif self.bn_before_weight:\n",
    "\t\t\t\tmodules['bn'] = nn.BatchNorm2d(in_channels)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmodules['bn'] = nn.BatchNorm2d(out_channels)\n",
    "\t\telse:\n",
    "\t\t\tmodules['bn'] = None\n",
    "\t\t# activation\n",
    "\t\tmodules['act'] = build_activation(self.act_func, self.ops_list[0] != 'act' and self.use_bn)\n",
    "\t\t# dropout\n",
    "\t\tif self.dropout_rate > 0:\n",
    "\t\t\tmodules['dropout'] = nn.Dropout2d(self.dropout_rate, inplace=True)\n",
    "\t\telse:\n",
    "\t\t\tmodules['dropout'] = None\n",
    "\t\t# weight\n",
    "\t\tmodules['weight'] = self.weight_op()\n",
    "\n",
    "\t\t# add modules\n",
    "\t\tfor op in self.ops_list:\n",
    "\t\t\tif modules[op] is None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telif op == 'weight':\n",
    "\t\t\t\t# dropout before weight operation\n",
    "\t\t\t\tif modules['dropout'] is not None:\n",
    "\t\t\t\t\tself.add_module('dropout', modules['dropout'])\n",
    "\t\t\t\tfor key in modules['weight']:\n",
    "\t\t\t\t\tself.add_module(key, modules['weight'][key])\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.add_module(op, modules[op])\n",
    "\n",
    "\t@property\n",
    "\tdef ops_list(self):\n",
    "\t\treturn self.ops_order.split('_')\n",
    "\n",
    "\t@property\n",
    "\tdef bn_before_weight(self):\n",
    "\t\tfor op in self.ops_list:\n",
    "\t\t\tif op == 'bn':\n",
    "\t\t\t\treturn True\n",
    "\t\t\telif op == 'weight':\n",
    "\t\t\t\treturn False\n",
    "\t\traise ValueError('Invalid ops_order: %s' % self.ops_order)\n",
    "\n",
    "\tdef weight_op(self):\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\t\"\"\" Methods defined in MyModule \"\"\"\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# similar to nn.Sequential\n",
    "\t\tfor module in self._modules.values():\n",
    "\t\t\tx = module(x)\n",
    "\t\treturn x\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'in_channels': self.in_channels,\n",
    "\t\t\t'out_channels': self.out_channels,\n",
    "\t\t\t'use_bn': self.use_bn,\n",
    "\t\t\t'act_func': self.act_func,\n",
    "\t\t\t'dropout_rate': self.dropout_rate,\n",
    "\t\t\t'ops_order': self.ops_order,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\n",
    "class ConvLayer(My2DLayer):\n",
    "\n",
    "\tdef __init__(self, in_channels, out_channels,\n",
    "\t             kernel_size=3, stride=1, dilation=1, groups=1, bias=False, has_shuffle=False, use_se=False,\n",
    "\t             use_bn=True, act_func='relu', dropout_rate=0, ops_order='weight_bn_act'):\n",
    "\t\t# default normal 3x3_Conv with bn and relu\n",
    "\t\tself.kernel_size = kernel_size\n",
    "\t\tself.stride = stride\n",
    "\t\tself.dilation = dilation\n",
    "\t\tself.groups = groups\n",
    "\t\tself.bias = bias\n",
    "\t\tself.has_shuffle = has_shuffle\n",
    "\t\tself.use_se = use_se\n",
    "\n",
    "\t\tsuper(ConvLayer, self).__init__(in_channels, out_channels, use_bn, act_func, dropout_rate, ops_order)\n",
    "\t\tif self.use_se:\n",
    "\t\t\tself.add_module('se', SEModule(self.out_channels))\n",
    "\n",
    "\tdef weight_op(self):\n",
    "\t\tpadding = get_same_padding(self.kernel_size)\n",
    "\t\tif isinstance(padding, int):\n",
    "\t\t\tpadding *= self.dilation\n",
    "\t\telse:\n",
    "\t\t\tpadding[0] *= self.dilation\n",
    "\t\t\tpadding[1] *= self.dilation\n",
    "\n",
    "\t\tweight_dict = OrderedDict({\n",
    "\t\t\t'conv': nn.Conv2d(\n",
    "\t\t\t\tself.in_channels, self.out_channels, kernel_size=self.kernel_size, stride=self.stride, padding=padding,\n",
    "\t\t\t\tdilation=self.dilation, groups=min_divisible_value(self.in_channels, self.groups), bias=self.bias\n",
    "\t\t\t)\n",
    "\t\t})\n",
    "\t\tif self.has_shuffle and self.groups > 1:\n",
    "\t\t\tweight_dict['shuffle'] = ShuffleLayer(self.groups)\n",
    "\n",
    "\t\treturn weight_dict\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\tif isinstance(self.kernel_size, int):\n",
    "\t\t\tkernel_size = (self.kernel_size, self.kernel_size)\n",
    "\t\telse:\n",
    "\t\t\tkernel_size = self.kernel_size\n",
    "\t\tif self.groups == 1:\n",
    "\t\t\tif self.dilation > 1:\n",
    "\t\t\t\tconv_str = '%dx%d_DilatedConv' % (kernel_size[0], kernel_size[1])\n",
    "\t\t\telse:\n",
    "\t\t\t\tconv_str = '%dx%d_Conv' % (kernel_size[0], kernel_size[1])\n",
    "\t\telse:\n",
    "\t\t\tif self.dilation > 1:\n",
    "\t\t\t\tconv_str = '%dx%d_DilatedGroupConv' % (kernel_size[0], kernel_size[1])\n",
    "\t\t\telse:\n",
    "\t\t\t\tconv_str = '%dx%d_GroupConv' % (kernel_size[0], kernel_size[1])\n",
    "\t\tconv_str += '_O%d' % self.out_channels\n",
    "\t\tif self.use_se:\n",
    "\t\t\tconv_str = 'SE_' + conv_str\n",
    "\t\tconv_str += '_' + self.act_func.upper()\n",
    "\t\tif self.use_bn:\n",
    "\t\t\tif isinstance(self.bn, nn.GroupNorm):\n",
    "\t\t\t\tconv_str += '_GN%d' % self.bn.num_groups\n",
    "\t\t\telif isinstance(self.bn, nn.BatchNorm2d):\n",
    "\t\t\t\tconv_str += '_BN'\n",
    "\t\treturn conv_str\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': ConvLayer.__name__,\n",
    "\t\t\t'kernel_size': self.kernel_size,\n",
    "\t\t\t'stride': self.stride,\n",
    "\t\t\t'dilation': self.dilation,\n",
    "\t\t\t'groups': self.groups,\n",
    "\t\t\t'bias': self.bias,\n",
    "\t\t\t'has_shuffle': self.has_shuffle,\n",
    "\t\t\t'use_se': self.use_se,\n",
    "\t\t\t**super(ConvLayer, self).config\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn ConvLayer(**config)\n",
    "\n",
    "\n",
    "class IdentityLayer(My2DLayer):\n",
    "\n",
    "\tdef __init__(self, in_channels, out_channels,\n",
    "\t             use_bn=False, act_func=None, dropout_rate=0, ops_order='weight_bn_act'):\n",
    "\t\tsuper(IdentityLayer, self).__init__(in_channels, out_channels, use_bn, act_func, dropout_rate, ops_order)\n",
    "\n",
    "\tdef weight_op(self):\n",
    "\t\treturn None\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\treturn 'Identity'\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': IdentityLayer.__name__,\n",
    "\t\t\t**super(IdentityLayer, self).config,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn IdentityLayer(**config)\n",
    "\n",
    "\n",
    "class LinearLayer(MyModule):\n",
    "\n",
    "\tdef __init__(self, in_features, out_features, bias=True,\n",
    "\t             use_bn=False, act_func=None, dropout_rate=0, ops_order='weight_bn_act'):\n",
    "\t\tsuper(LinearLayer, self).__init__()\n",
    "\n",
    "\t\tself.in_features = in_features\n",
    "\t\tself.out_features = out_features\n",
    "\t\tself.bias = bias\n",
    "\n",
    "\t\tself.use_bn = use_bn\n",
    "\t\tself.act_func = act_func\n",
    "\t\tself.dropout_rate = dropout_rate\n",
    "\t\tself.ops_order = ops_order\n",
    "\n",
    "\t\t\"\"\" modules \"\"\"\n",
    "\t\tmodules = {}\n",
    "\t\t# batch norm\n",
    "\t\tif self.use_bn:\n",
    "\t\t\tif self.bn_before_weight:\n",
    "\t\t\t\tmodules['bn'] = nn.BatchNorm1d(in_features)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmodules['bn'] = nn.BatchNorm1d(out_features)\n",
    "\t\telse:\n",
    "\t\t\tmodules['bn'] = None\n",
    "\t\t# activation\n",
    "\t\tmodules['act'] = build_activation(self.act_func, self.ops_list[0] != 'act')\n",
    "\t\t# dropout\n",
    "\t\tif self.dropout_rate > 0:\n",
    "\t\t\tmodules['dropout'] = nn.Dropout(self.dropout_rate, inplace=True)\n",
    "\t\telse:\n",
    "\t\t\tmodules['dropout'] = None\n",
    "\t\t# linear\n",
    "\t\tmodules['weight'] = {'linear': nn.Linear(self.in_features, self.out_features, self.bias)}\n",
    "\n",
    "\t\t# add modules\n",
    "\t\tfor op in self.ops_list:\n",
    "\t\t\tif modules[op] is None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telif op == 'weight':\n",
    "\t\t\t\tif modules['dropout'] is not None:\n",
    "\t\t\t\t\tself.add_module('dropout', modules['dropout'])\n",
    "\t\t\t\tfor key in modules['weight']:\n",
    "\t\t\t\t\tself.add_module(key, modules['weight'][key])\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.add_module(op, modules[op])\n",
    "\n",
    "\t@property\n",
    "\tdef ops_list(self):\n",
    "\t\treturn self.ops_order.split('_')\n",
    "\n",
    "\t@property\n",
    "\tdef bn_before_weight(self):\n",
    "\t\tfor op in self.ops_list:\n",
    "\t\t\tif op == 'bn':\n",
    "\t\t\t\treturn True\n",
    "\t\t\telif op == 'weight':\n",
    "\t\t\t\treturn False\n",
    "\t\traise ValueError('Invalid ops_order: %s' % self.ops_order)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tfor module in self._modules.values():\n",
    "\t\t\tx = module(x)\n",
    "\t\treturn x\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\treturn '%dx%d_Linear' % (self.in_features, self.out_features)\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': LinearLayer.__name__,\n",
    "\t\t\t'in_features': self.in_features,\n",
    "\t\t\t'out_features': self.out_features,\n",
    "\t\t\t'bias': self.bias,\n",
    "\t\t\t'use_bn': self.use_bn,\n",
    "\t\t\t'act_func': self.act_func,\n",
    "\t\t\t'dropout_rate': self.dropout_rate,\n",
    "\t\t\t'ops_order': self.ops_order,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn LinearLayer(**config)\n",
    "\n",
    "\n",
    "class MultiHeadLinearLayer(MyModule):\n",
    "\n",
    "\tdef __init__(self, in_features, out_features, num_heads=1, bias=True, dropout_rate=0):\n",
    "\t\tsuper(MultiHeadLinearLayer, self).__init__()\n",
    "\t\tself.in_features = in_features\n",
    "\t\tself.out_features = out_features\n",
    "\t\tself.num_heads = num_heads\n",
    "\n",
    "\t\tself.bias = bias\n",
    "\t\tself.dropout_rate = dropout_rate\n",
    "\n",
    "\t\tif self.dropout_rate > 0:\n",
    "\t\t\tself.dropout = nn.Dropout(self.dropout_rate, inplace=True)\n",
    "\t\telse:\n",
    "\t\t\tself.dropout = None\n",
    "\n",
    "\t\tself.layers = nn.ModuleList()\n",
    "\t\tfor k in range(num_heads):\n",
    "\t\t\tlayer = nn.Linear(in_features, out_features, self.bias)\n",
    "\t\t\tself.layers.append(layer)\n",
    "\n",
    "\tdef forward(self, inputs):\n",
    "\t\tif self.dropout is not None:\n",
    "\t\t\tinputs = self.dropout(inputs)\n",
    "\n",
    "\t\toutputs = []\n",
    "\t\tfor layer in self.layers:\n",
    "\t\t\toutput = layer.forward(inputs)\n",
    "\t\t\toutputs.append(output)\n",
    "\n",
    "\t\toutputs = torch.stack(outputs, dim=1)\n",
    "\t\treturn outputs\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\treturn self.__repr__()\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': MultiHeadLinearLayer.__name__,\n",
    "\t\t\t'in_features': self.in_features,\n",
    "\t\t\t'out_features': self.out_features,\n",
    "\t\t\t'num_heads': self.num_heads,\n",
    "\t\t\t'bias': self.bias,\n",
    "\t\t\t'dropout_rate': self.dropout_rate,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn MultiHeadLinearLayer(**config)\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn 'MultiHeadLinear(in_features=%d, out_features=%d, num_heads=%d, bias=%s, dropout_rate=%s)' % (\n",
    "\t\t\tself.in_features, self.out_features, self.num_heads, self.bias, self.dropout_rate\n",
    "\t\t)\n",
    "\n",
    "\n",
    "class ZeroLayer(MyModule):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(ZeroLayer, self).__init__()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\traise ValueError\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\treturn 'Zero'\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': ZeroLayer.__name__,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn ZeroLayer()\n",
    "\n",
    "\n",
    "class MBConvLayer(MyModule):\n",
    "\n",
    "\tdef __init__(self, in_channels, out_channels,\n",
    "\t             kernel_size=3, stride=1, expand_ratio=6, mid_channels=None, act_func='relu6', use_se=False,\n",
    "\t             groups=None):\n",
    "\t\tsuper(MBConvLayer, self).__init__()\n",
    "\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.out_channels = out_channels\n",
    "\n",
    "\t\tself.kernel_size = kernel_size\n",
    "\t\tself.stride = stride\n",
    "\t\tself.expand_ratio = expand_ratio\n",
    "\t\tself.mid_channels = mid_channels\n",
    "\t\tself.act_func = act_func\n",
    "\t\tself.use_se = use_se\n",
    "\t\tself.groups = groups\n",
    "\n",
    "\t\tif self.mid_channels is None:\n",
    "\t\t\tfeature_dim = round(self.in_channels * self.expand_ratio)\n",
    "\t\telse:\n",
    "\t\t\tfeature_dim = self.mid_channels\n",
    "\n",
    "\t\tif self.expand_ratio == 1:\n",
    "\t\t\tself.inverted_bottleneck = None\n",
    "\t\telse:\n",
    "\t\t\tself.inverted_bottleneck = nn.Sequential(OrderedDict([\n",
    "\t\t\t\t('conv', nn.Conv2d(self.in_channels, feature_dim, 1, 1, 0, bias=False)),\n",
    "\t\t\t\t('bn', nn.BatchNorm2d(feature_dim)),\n",
    "\t\t\t\t('act', build_activation(self.act_func, inplace=True)),\n",
    "\t\t\t]))\n",
    "\n",
    "\t\tpad = get_same_padding(self.kernel_size)\n",
    "\t\tgroups = feature_dim if self.groups is None else min_divisible_value(feature_dim, self.groups)\n",
    "\t\tdepth_conv_modules = [\n",
    "\t\t\t('conv', nn.Conv2d(feature_dim, feature_dim, kernel_size, stride, pad, groups=groups, bias=False)),\n",
    "\t\t\t('bn', nn.BatchNorm2d(feature_dim)),\n",
    "\t\t\t('act', build_activation(self.act_func, inplace=True))\n",
    "\t\t]\n",
    "\t\tif self.use_se:\n",
    "\t\t\tdepth_conv_modules.append(('se', SEModule(feature_dim)))\n",
    "\t\tself.depth_conv = nn.Sequential(OrderedDict(depth_conv_modules))\n",
    "\n",
    "\t\tself.point_linear = nn.Sequential(OrderedDict([\n",
    "\t\t\t('conv', nn.Conv2d(feature_dim, out_channels, 1, 1, 0, bias=False)),\n",
    "\t\t\t('bn', nn.BatchNorm2d(out_channels)),\n",
    "\t\t]))\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif self.inverted_bottleneck:\n",
    "\t\t\tx = self.inverted_bottleneck(x)\n",
    "\t\tx = self.depth_conv(x)\n",
    "\t\tx = self.point_linear(x)\n",
    "\t\treturn x\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\tif self.mid_channels is None:\n",
    "\t\t\texpand_ratio = self.expand_ratio\n",
    "\t\telse:\n",
    "\t\t\texpand_ratio = self.mid_channels // self.in_channels\n",
    "\t\tlayer_str = '%dx%d_MBConv%d_%s' % (self.kernel_size, self.kernel_size, expand_ratio, self.act_func.upper())\n",
    "\t\tif self.use_se:\n",
    "\t\t\tlayer_str = 'SE_' + layer_str\n",
    "\t\tlayer_str += '_O%d' % self.out_channels\n",
    "\t\tif self.groups is not None:\n",
    "\t\t\tlayer_str += '_G%d' % self.groups\n",
    "\t\tif isinstance(self.point_linear.bn, nn.GroupNorm):\n",
    "\t\t\tlayer_str += '_GN%d' % self.point_linear.bn.num_groups\n",
    "\t\telif isinstance(self.point_linear.bn, nn.BatchNorm2d):\n",
    "\t\t\tlayer_str += '_BN'\n",
    "\n",
    "\t\treturn layer_str\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': MBConvLayer.__name__,\n",
    "\t\t\t'in_channels': self.in_channels,\n",
    "\t\t\t'out_channels': self.out_channels,\n",
    "\t\t\t'kernel_size': self.kernel_size,\n",
    "\t\t\t'stride': self.stride,\n",
    "\t\t\t'expand_ratio': self.expand_ratio,\n",
    "\t\t\t'mid_channels': self.mid_channels,\n",
    "\t\t\t'act_func': self.act_func,\n",
    "\t\t\t'use_se': self.use_se,\n",
    "\t\t\t'groups': self.groups,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn MBConvLayer(**config)\n",
    "\n",
    "\n",
    "class ResidualBlock(MyModule):\n",
    "\n",
    "\tdef __init__(self, conv, shortcut):\n",
    "\t\tsuper(ResidualBlock, self).__init__()\n",
    "\n",
    "\t\tself.conv = conv\n",
    "\t\tself.shortcut = shortcut\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif self.conv is None or isinstance(self.conv, ZeroLayer):\n",
    "\t\t\tres = x\n",
    "\t\telif self.shortcut is None or isinstance(self.shortcut, ZeroLayer):\n",
    "\t\t\tres = self.conv(x)\n",
    "\t\telse:\n",
    "\t\t\tres = self.conv(x) + self.shortcut(x)\n",
    "\t\treturn res\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\treturn '(%s, %s)' % (\n",
    "\t\t\tself.conv.module_str if self.conv is not None else None,\n",
    "\t\t\tself.shortcut.module_str if self.shortcut is not None else None\n",
    "\t\t)\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': ResidualBlock.__name__,\n",
    "\t\t\t'conv': self.conv.config if self.conv is not None else None,\n",
    "\t\t\t'shortcut': self.shortcut.config if self.shortcut is not None else None,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\tconv_config = config['conv'] if 'conv' in config else config['mobile_inverted_conv']\n",
    "\t\tconv = set_layer_from_config(conv_config)\n",
    "\t\tshortcut = set_layer_from_config(config['shortcut'])\n",
    "\t\treturn ResidualBlock(conv, shortcut)\n",
    "\n",
    "\t@property\n",
    "\tdef mobile_inverted_conv(self):\n",
    "\t\treturn self.conv\n",
    "\n",
    "\n",
    "class ResNetBottleneckBlock(MyModule):\n",
    "\n",
    "\tdef __init__(self, in_channels, out_channels,\n",
    "\t             kernel_size=3, stride=1, expand_ratio=0.25, mid_channels=None, act_func='relu', groups=1,\n",
    "\t             downsample_mode='avgpool_conv'):\n",
    "\t\tsuper(ResNetBottleneckBlock, self).__init__()\n",
    "\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.out_channels = out_channels\n",
    "\n",
    "\t\tself.kernel_size = kernel_size\n",
    "\t\tself.stride = stride\n",
    "\t\tself.expand_ratio = expand_ratio\n",
    "\t\tself.mid_channels = mid_channels\n",
    "\t\tself.act_func = act_func\n",
    "\t\tself.groups = groups\n",
    "\n",
    "\t\tself.downsample_mode = downsample_mode\n",
    "\n",
    "\t\tif self.mid_channels is None:\n",
    "\t\t\tfeature_dim = round(self.out_channels * self.expand_ratio)\n",
    "\t\telse:\n",
    "\t\t\tfeature_dim = self.mid_channels\n",
    "\n",
    "\t\tfeature_dim = make_divisible(feature_dim, MyNetwork.CHANNEL_DIVISIBLE)\n",
    "\t\tself.mid_channels = feature_dim\n",
    "\n",
    "\t\t# build modules\n",
    "\t\tself.conv1 = nn.Sequential(OrderedDict([\n",
    "\t\t\t('conv', nn.Conv2d(self.in_channels, feature_dim, 1, 1, 0, bias=False)),\n",
    "\t\t\t('bn', nn.BatchNorm2d(feature_dim)),\n",
    "\t\t\t('act', build_activation(self.act_func, inplace=True)),\n",
    "\t\t]))\n",
    "\n",
    "\t\tpad = get_same_padding(self.kernel_size)\n",
    "\t\tself.conv2 = nn.Sequential(OrderedDict([\n",
    "\t\t\t('conv', nn.Conv2d(feature_dim, feature_dim, kernel_size, stride, pad, groups=groups, bias=False)),\n",
    "\t\t\t('bn', nn.BatchNorm2d(feature_dim)),\n",
    "\t\t\t('act', build_activation(self.act_func, inplace=True))\n",
    "\t\t]))\n",
    "\n",
    "\t\tself.conv3 = nn.Sequential(OrderedDict([\n",
    "\t\t\t('conv', nn.Conv2d(feature_dim, self.out_channels, 1, 1, 0, bias=False)),\n",
    "\t\t\t('bn', nn.BatchNorm2d(self.out_channels)),\n",
    "\t\t]))\n",
    "\n",
    "\t\tif stride == 1 and in_channels == out_channels:\n",
    "\t\t\tself.downsample = IdentityLayer(in_channels, out_channels)\n",
    "\t\telif self.downsample_mode == 'conv':\n",
    "\t\t\tself.downsample = nn.Sequential(OrderedDict([\n",
    "\t\t\t\t('conv', nn.Conv2d(in_channels, out_channels, 1, stride, 0, bias=False)),\n",
    "\t\t\t\t('bn', nn.BatchNorm2d(out_channels)),\n",
    "\t\t\t]))\n",
    "\t\telif self.downsample_mode == 'avgpool_conv':\n",
    "\t\t\tself.downsample = nn.Sequential(OrderedDict([\n",
    "\t\t\t\t('avg_pool', nn.AvgPool2d(kernel_size=stride, stride=stride, padding=0, ceil_mode=True)),\n",
    "\t\t\t\t('conv', nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False)),\n",
    "\t\t\t\t('bn', nn.BatchNorm2d(out_channels)),\n",
    "\t\t\t]))\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError\n",
    "\n",
    "\t\tself.final_act = build_activation(self.act_func, inplace=True)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresidual = self.downsample(x)\n",
    "\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.conv3(x)\n",
    "\n",
    "\t\tx = x + residual\n",
    "\t\tx = self.final_act(x)\n",
    "\t\treturn x\n",
    "\n",
    "\t@property\n",
    "\tdef module_str(self):\n",
    "\t\treturn '(%s, %s)' % (\n",
    "\t\t\t'%dx%d_BottleneckConv_%d->%d->%d_S%d_G%d' % (\n",
    "\t\t\t\tself.kernel_size, self.kernel_size, self.in_channels, self.mid_channels, self.out_channels,\n",
    "\t\t\t\tself.stride, self.groups\n",
    "\t\t\t),\n",
    "\t\t\t'Identity' if isinstance(self.downsample, IdentityLayer) else self.downsample_mode,\n",
    "\t\t)\n",
    "\n",
    "\t@property\n",
    "\tdef config(self):\n",
    "\t\treturn {\n",
    "\t\t\t'name': ResNetBottleneckBlock.__name__,\n",
    "\t\t\t'in_channels': self.in_channels,\n",
    "\t\t\t'out_channels': self.out_channels,\n",
    "\t\t\t'kernel_size': self.kernel_size,\n",
    "\t\t\t'stride': self.stride,\n",
    "\t\t\t'expand_ratio': self.expand_ratio,\n",
    "\t\t\t'mid_channels': self.mid_channels,\n",
    "\t\t\t'act_func': self.act_func,\n",
    "\t\t\t'groups': self.groups,\n",
    "\t\t\t'downsample_mode': self.downsample_mode,\n",
    "\t\t}\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build_from_config(config):\n",
    "\t\treturn ResNetBottleneckBlock(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_resolution = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block, input_size, in_channels, out_channels, expand_ratio, kernel_size, stride, act, se\n",
    "\n",
    "configurations = [\n",
    "\t\t\t(ConvLayer, base_resolution, 3, 16, 3, 2, 'relu'),\n",
    "\t\t\t(ResidualBlock, base_resolution // 2, 16, 16, [1], [3, 5, 7], 1, 'relu', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 2, 16, 24, [3, 4, 6], [3, 5, 7], 2, 'relu', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 4, 24, 24, [3, 4, 6], [3, 5, 7], 1, 'relu', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 4, 24, 24, [3, 4, 6], [3, 5, 7], 1, 'relu', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 4, 24, 24, [3, 4, 6], [3, 5, 7], 1, 'relu', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 4, 24, 40, [3, 4, 6], [3, 5, 7], 2, 'relu', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 8, 40, 40, [3, 4, 6], [3, 5, 7], 1, 'relu', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 8, 40, 40, [3, 4, 6], [3, 5, 7], 1, 'relu', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 8, 40, 40, [3, 4, 6], [3, 5, 7], 1, 'relu', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 8, 40, 80, [3, 4, 6], [3, 5, 7], 2, 'h_swish', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 80, 80, [3, 4, 6], [3, 5, 7], 1, 'h_swish', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 80, 80, [3, 4, 6], [3, 5, 7], 1, 'h_swish', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 80, 80, [3, 4, 6], [3, 5, 7], 1, 'h_swish', False),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 80, 112, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 112, 112, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 112, 112, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 112, 112, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 16, 112, 160, [3, 4, 6], [3, 5, 7], 2, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 32, 160, 160, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 32, 160, 160, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ResidualBlock, base_resolution // 32, 160, 160, [3, 4, 6], [3, 5, 7], 1, 'h_swish', True),\n",
    "\t\t\t(ConvLayer, base_resolution // 32, 160, 960, 1, 1, 'h_swish'),\n",
    "\t\t\t(ConvLayer, 1, 960, 1280, 1, 1, 'h_swish'),\n",
    "\t\t\t(LinearLayer, 1, 1280, 1000, 1, 1),\n",
    "\t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'Conv2D': [],\n",
    "    'BatchNorm2d': [],\n",
    "    'ReLU': [],\n",
    "    'MaxPool2d': [],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'queue' from 'torch._six' (/home/shikhar.srivastava/miniconda3/envs/pytorch_19/lib/python3.7/site-packages/torch/_six.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_98356/4003677323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mofa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/l/users/shikhar.srivastava/workspace/TANS/ofa/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mflops_counter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmy_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/l/users/shikhar.srivastava/workspace/TANS/ofa/utils/my_dataloader/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmy_data_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmy_data_worker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmy_distributed_sampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmy_random_resize_crop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/l/users/shikhar.srivastava/workspace/TANS/ofa/utils/my_dataloader/my_data_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterableDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'queue' from 'torch._six' (/home/shikhar.srivastava/miniconda3/envs/pytorch_19/lib/python3.7/site-packages/torch/_six.py)"
     ]
    }
   ],
   "source": [
    "from ofa.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(len(configurations)):\n",
    "\tconfig = configurations[layer_idx]\n",
    "\top_type = config[0]\n",
    "\tif op_type == ResidualBlock:\n",
    "\t\t_, input_size, in_channels, out_channels, expand_list, ks_list, stride, act, se = config\n",
    "\t\tin_channels = int(round(in_channels * self.multiplier))\n",
    "\t\tout_channels = int(round(out_channels * self.multiplier))\n",
    "\t\ttemplate_config = {\n",
    "\t\t\t'name': ResidualBlock.__name__,\n",
    "\t\t\t'mobile_inverted_conv': {\n",
    "\t\t\t\t'name': MBConvLayer.__name__,\n",
    "\t\t\t\t'in_channels': in_channels,\n",
    "\t\t\t\t'out_channels': out_channels,\n",
    "\t\t\t\t'kernel_size': kernel_size,\n",
    "\t\t\t\t'stride': stride,\n",
    "\t\t\t\t'expand_ratio': 0,\n",
    "\t\t\t\t# 'mid_channels': None,\n",
    "\t\t\t\t'act_func': act,\n",
    "\t\t\t\t'use_se': se,\n",
    "\t\t\t},\n",
    "\t\t\t'shortcut': {\n",
    "\t\t\t\t'name': IdentityLayer.__name__,\n",
    "\t\t\t\t'in_channels': in_channels,\n",
    "\t\t\t\t'out_channels': out_channels,\n",
    "\t\t\t} if (in_channels == out_channels and stride == 1) else None\n",
    "\t\t}\n",
    "\n",
    "\telif op_type == ConvLayer:\n",
    "\t\t_, input_size, in_channels, out_channels, kernel_size, stride, activation = config\n",
    "\t\tin_channels = int(round(in_channels * self.multiplier))\n",
    "\t\tout_channels = int(round(out_channels * self.multiplier))\n",
    "\t\tbuild_config = {\n",
    "\t\t\t# 'name': ConvLayer.__name__,\n",
    "\t\t\t'in_channels': in_channels,\n",
    "\t\t\t'out_channels': out_channels,\n",
    "\t\t\t'kernel_size': kernel_size,\n",
    "\t\t\t'stride': stride,\n",
    "\t\t\t'dilation': 1,\n",
    "\t\t\t'groups': 1,\n",
    "\t\t\t'bias': False,\n",
    "\t\t\t'use_bn': True,\n",
    "\t\t\t'has_shuffle': False,\n",
    "\t\t\t'act_func': activation,\n",
    "\t\t}\n",
    "\t\tlayer = ConvLayer.build_from_config(build_config)\n",
    "\t\tinput_shape = (batch_size, in_channels, input_size, input_size)\n",
    "\n",
    "\t\tif self.pred_type == 'flops':\n",
    "\t\t\tmeasure_result = self.measure_single_layer_flops(layer, input_shape) / batch_size\n",
    "\t\telif self.pred_type == 'latency':\n",
    "\t\t\tmeasure_result = self.measure_single_layer_latency(layer, input_shape)\n",
    "\n",
    "\t\tefficiency_dict['other_blocks'][layer_idx] = measure_result\n",
    "\n",
    "\telif op_type == LinearLayer:\n",
    "\t\t_, input_size, in_channels, out_channels, kernel_size, stride = config\n",
    "\t\tin_channels = int(round(in_channels * self.multiplier))\n",
    "\t\tout_channels = int(round(out_channels * self.multiplier))\n",
    "\t\tbuild_config = {\n",
    "\t\t\t# 'name': LinearLayer.__name__,\n",
    "\t\t\t'in_features': in_channels,\n",
    "\t\t\t'out_features': out_channels\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Read pt file from path \n",
    "#path = '/l/users/shikhar.srivastava/data/ofa/www.dropbox.com/s/1qbsgjqanxgw2ji/p_m_train.pt'\n",
    "path ='/l/users/shikhar.srivastava/data/ofa/www.dropbox.com/s/gb0xe86zulsjs99/p_mod_zoo.pt'\n",
    "files = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset', 'acc', 'n_params', 'topol', 'f_emb'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['topol'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.6876, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.2272, -0.3029, -0.1857,  ..., -0.1262, -0.0000, -0.3728]),\n",
       " tensor([-0.2580, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  1.3191]),\n",
       " tensor([73.9549, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([7.1190, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, 1.5584, -0.0000]),\n",
       " tensor([ 3.9480, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0483]),\n",
       " tensor([15.1548, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1450, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([12.9656, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3112,  1.1543, -0.0000,  ..., -0.0000, -0.3218, -0.0000]),\n",
       " tensor([ 1.0323, -0.0000, -0.3701,  ..., -0.0000, -0.0000, -0.1281]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3743]),\n",
       " tensor([ -0.0000, 369.4255,  -0.0000,  ...,  -0.0000,  -0.0000, 783.1443]),\n",
       " tensor([3.6715, -0.0000, -0.0000,  ..., -0.0000, 4.8094, -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., 8.3499, -0.0000, -0.0000]),\n",
       " tensor([ 4.6756, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 13.2243]),\n",
       " tensor([-0.3129, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0158,  0.8457, -0.0000,  ..., -0.0560, -0.0000, -0.0000]),\n",
       " tensor([-0.2387, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([  -0.0000,  344.7549,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1178.3499]),\n",
       " tensor([-0.1318, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0475, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3739]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([7.1487, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.7971, -0.3727, -0.2837,  ..., -0.3652, -0.3014,  0.9150]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([75.4701, 87.6327, -0.0000,  ..., -0.0000, -0.0000, 45.9882]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([168.2882,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.3653, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0000, -0.0000, -0.1459,  ..., -0.0000, -0.0000,  2.7607]),\n",
       " tensor([72.7155, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([1817.0599,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3707, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([2.1221, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([6.1940, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0746, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0310]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.2909,  0.0492, -0.3445,  ...,  0.0140, -0.3324,  0.2995]),\n",
       " tensor([-0.1578, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([67.3983, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.3390, -0.2534, -0.3013,  ..., -0.0000, -0.0000, -0.3663]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([1384.8149,  626.0353,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "          627.6306]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 14.9472]),\n",
       " tensor([-0.1173, -0.2462,  0.2171,  ..., -0.0000, -0.0000,  3.5474]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 12.5171]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 3.4871, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.2339]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.4785, -0.0000, -0.3715,  ..., -0.0000, -0.0000, -0.1191]),\n",
       " tensor([24.9505, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3736, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  1.1422]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 1.1207, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3566]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3573, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3351]),\n",
       " tensor([-0.2673, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.1092]),\n",
       " tensor([-0.2865, -0.0000, -0.0000,  ..., -0.0000, -0.2465, -0.0000]),\n",
       " tensor([0.7113, -0.0000, 0.3211,  ..., -0.0000, -0.0000, 0.2443]),\n",
       " tensor([1590.3285,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([0.3406, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ -0.0000,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 523.7716]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([5742.3218,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         8181.5503]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.2650, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3707]),\n",
       " tensor([63.4659, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2070, -0.0000, -0.3426,  ..., -0.3731, -0.3642,  1.8961]),\n",
       " tensor([-0.1629, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([343.8662,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 0.3203, -0.2910, -0.1606,  ..., -0.1830, -0.0000,  0.4762]),\n",
       " tensor([10.1938, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2497, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([51.2848,  0.1265, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3612, -0.0000, -0.0000,  ..., -0.0000,  0.8615,  1.1494]),\n",
       " tensor([1.2004, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 0.3256]),\n",
       " tensor([9.7415, 7.1616, -0.0000,  ..., -0.0000, -0.0000, 3.3257]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 65.5261]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0218,  0.3494, -0.1408,  ..., -0.0597,  0.2927, -0.1659]),\n",
       " tensor([-3.0489e-04,  5.9865e-01,  1.2787e-01,  ..., -0.0000e+00,\n",
       "         -0.0000e+00,  9.8457e-01]),\n",
       " tensor([11.7354, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  3.5293]),\n",
       " tensor([ 1.8917, -0.2036, -0.0000,  ..., -0.0000, -0.2916,  2.0192]),\n",
       " tensor([-0.2434, -0.1211, -0.3357,  ..., -0.2367, -0.3605,  0.1600]),\n",
       " tensor([-0.1226, -0.0011, -0.1069,  ..., -0.0115,  0.5366, -0.0172]),\n",
       " tensor([-0.0955, -0.2792, -0.2548,  ..., -0.2315, -0.1562, -0.0829]),\n",
       " tensor([-0.3190, -0.0619, -0.2040,  ..., -0.3169, -0.0998, -0.1264]),\n",
       " tensor([-0.3000, -0.0000, -0.3524,  ..., -0.2534, -0.3597, -0.3734]),\n",
       " tensor([-0.2669, -0.1254, -0.1047,  ..., -0.2100, -0.3645, -0.2788]),\n",
       " tensor([-0.0641, -0.2090, -0.2588,  ..., -0.0753, -0.1130, -0.3738]),\n",
       " tensor([-0.3289, -0.0000, -0.0000,  ..., -0.2364, -0.0000, -0.0000]),\n",
       " tensor([-0.0425, -0.2432, -0.2587,  ..., -0.3748, -0.3153, -0.3600]),\n",
       " tensor([ 0.2804, -0.3147, -0.3526,  ..., -0.2554, -0.0000,  0.7173]),\n",
       " tensor([-0.1529,  0.1952, -0.1047,  ..., -0.2567,  0.1997,  0.0153]),\n",
       " tensor([-0.2709,  0.1317, -0.0000,  ..., -0.3234, -0.0000, -0.3378]),\n",
       " tensor([-0.0229, -0.2140, -0.0783,  ..., -0.1067, -0.0047, -0.0785]),\n",
       " tensor([ 0.3288, -0.2704, -0.0000,  ..., -0.1491, -0.0140,  0.0165]),\n",
       " tensor([-0.1827, -0.3149, -0.3395,  ..., -0.0457, -0.0000, -0.0048]),\n",
       " tensor([-0.3728, -0.3159, -0.3015,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1913, -0.2415, -0.3454,  ..., -0.3255, -0.2331, -0.3747]),\n",
       " tensor([-0.1448,  0.5118, -0.0211,  ..., -0.2714, -0.0929, -0.3284]),\n",
       " tensor([-0.0048, -0.1712, -0.3713,  ..., -0.2450, -0.1094, -0.3255]),\n",
       " tensor([-0.1209,  0.1133, -0.3301,  ..., -0.3711, -0.2696, -0.1024]),\n",
       " tensor([-0.2002, -0.3388, -0.2809,  ..., -0.0404, -0.3453, -0.3084]),\n",
       " tensor([-0.1408,  0.0289, -0.2170,  ..., -0.1912, -0.2815, -0.3306]),\n",
       " tensor([-0.2324,  0.0063, -0.2395,  ..., -0.3130, -0.2613, -0.1700]),\n",
       " tensor([-0.2431, -0.0336, -0.3458,  ..., -0.0606, -0.2830, -0.3559]),\n",
       " tensor([-0.1965,  0.0667, -0.1363,  ..., -0.0789, -0.2503, -0.2015]),\n",
       " tensor([-0.1416, -0.0255, -0.1768,  ..., -0.1373, -0.1113, -0.1312]),\n",
       " tensor([-0.0293,  0.2368, -0.1953,  ..., -0.2734,  0.0022, -0.1447]),\n",
       " tensor([-0.3717, -0.0633, -0.3361,  ..., -0.3298, -0.1894, -0.2607]),\n",
       " tensor([-0.0543, -0.2738, -0.1394,  ..., -0.2514, -0.3520, -0.0340]),\n",
       " tensor([-0.3224, -0.1558, -0.3316,  ..., -0.3733, -0.0000, -0.3090]),\n",
       " tensor([28.4618, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3744]),\n",
       " tensor([-0.0416, -0.0000, -0.0000,  ..., -0.0987, -0.0783, -0.3747]),\n",
       " tensor([ 0.0106, -0.3605, -0.2772,  ..., -0.2346, -0.3397, -0.2085]),\n",
       " tensor([-0.0039, -0.0966, -0.0697,  ...,  0.0343, -0.2831, -0.2527]),\n",
       " tensor([-0.3634, -0.0930, -0.2776,  ..., -0.0592, -0.3684, -0.3114]),\n",
       " tensor([-0.1050, -0.3441, -0.3327,  ..., -0.0177,  0.1189, -0.3532]),\n",
       " tensor([-0.0514,  0.1999,  0.1062,  ..., -0.0550,  0.0141, -0.1707]),\n",
       " tensor([ 0.0020,  0.0678,  0.0317,  ..., -0.2748, -0.3748,  0.3842]),\n",
       " tensor([-0.0058,  0.2467, -0.2256,  ..., -0.2681,  0.1948, -0.2191]),\n",
       " tensor([-0.0646,  0.1321, -0.2027,  ..., -0.2225, -0.1154, -0.0428]),\n",
       " tensor([-0.1718, -0.1617, -0.2590,  ..., -0.3332, -0.2050, -0.3090]),\n",
       " tensor([-0.1115, -0.0477, -0.2306,  ..., -0.2117, -0.2739, -0.0930]),\n",
       " tensor([-0.0985, -0.0951, -0.2531,  ..., -0.2780,  0.1068, -0.1432]),\n",
       " tensor([-0.1781,  0.3951, -0.3613,  ..., -0.3737,  0.4179, -0.2232]),\n",
       " tensor([-0.1250, -0.0569, -0.3232,  ..., -0.2822, -0.3600, -0.2357]),\n",
       " tensor([ 0.0097, -0.1294,  0.0460,  ..., -0.1726,  0.3032, -0.0468]),\n",
       " tensor([43.0072, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0005,  0.2213, -0.1066,  ..., -0.1936, -0.1109, -0.0519]),\n",
       " tensor([-0.1383, -0.2984, -0.0000,  ...,  1.2403, -0.3744, -0.2199]),\n",
       " tensor([ 0.0807,  0.8123, -0.1134,  ..., -0.2111, -0.1586, -0.3286]),\n",
       " tensor([-0.0344,  0.0864, -0.3208,  ..., -0.3597, -0.3460, -0.1150]),\n",
       " tensor([-0.0945,  0.0829, -0.0548,  ..., -0.0406, -0.3570, -0.0375]),\n",
       " tensor([-0.0031,  0.0285, -0.3337,  ..., -0.1759, -0.1681, -0.1710]),\n",
       " tensor([ 2.8606, -0.0233, -0.0000,  ..., -0.0000, -0.3576, -0.0000]),\n",
       " tensor([-0.1406,  0.0421, -0.1629,  ..., -0.3008, -0.3539, -0.2365]),\n",
       " tensor([ 0.0080,  0.0032, -0.1146,  ..., -0.0927, -0.1507,  0.0181]),\n",
       " tensor([ 2.9486, -0.0000, -0.3505,  ..., -0.0000,  0.4332, -0.3285]),\n",
       " tensor([-0.1278, -0.1440, -0.3714,  ..., -0.1398, -0.0286, -0.2986]),\n",
       " tensor([ 77.8736,  -0.0000, 118.8173,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 0.0143, -0.0613, -0.3679,  ..., -0.3693, -0.3518, -0.3071]),\n",
       " tensor([-0.0455,  0.2073, -0.1408,  ..., -0.3545,  0.0311, -0.1790]),\n",
       " tensor([4.0373, -0.0000, 0.4045,  ..., 0.0638, -0.0000, 3.7404]),\n",
       " tensor([-0.2692, -0.3728,  0.0427,  ..., -0.1936, -0.1094, -0.0000]),\n",
       " tensor([ 0.1192, -0.3661, -0.3740,  ..., -0.3711,  0.3780, -0.3463]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3654,  0.1875, -0.3379,  ..., -0.0000, -0.3101, -0.3113]),\n",
       " tensor([-0.1907,  0.0969, -0.1581,  ..., -0.1195,  0.3783, -0.1512]),\n",
       " tensor([ 0.1217, -0.1240, -0.3463,  ..., -0.3127, -0.3699, -0.2962]),\n",
       " tensor([ 0.1160, -0.0042, -0.0709,  ..., -0.3673, -0.2451, -0.3344]),\n",
       " tensor([-0.1158, -0.3179, -0.3748,  ..., -0.2847, -0.0000, -0.3749]),\n",
       " tensor([525.9899,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 599.0406]),\n",
       " tensor([-0.1866, -0.0760, -0.1959,  ..., -0.0380, -0.0151, -0.2860]),\n",
       " tensor([ 0.5449, -0.1437, -0.0000,  ..., -0.3067, -0.3719, -0.3321]),\n",
       " tensor([-0.0007, -0.1545, -0.1210,  ...,  0.0263, -0.0625, -0.0925]),\n",
       " tensor([ 0.0402, -0.3388, -0.1885,  ..., -0.1730, -0.1288, -0.2074]),\n",
       " tensor([-0.0025,  0.0728, -0.0970,  ..., -0.2451, -0.3739,  0.1483]),\n",
       " tensor([-0.1779, -0.1646, -0.0705,  ...,  0.0058, -0.0054, -0.1096]),\n",
       " tensor([-0.1943, -0.3303, -0.2530,  ..., -0.3685, -0.2696, -0.3558]),\n",
       " tensor([-0.2212,  0.0093, -0.2291,  ..., -0.3571, -0.3722, -0.1906]),\n",
       " tensor([-0.1599,  0.1035, -0.3560,  ...,  0.0947,  0.0923, -0.1806]),\n",
       " tensor([-0.0251,  0.1232, -0.3117,  ..., -0.3395,  0.1895, -0.1606]),\n",
       " tensor([-0.0252, -0.0888, -0.2781,  ..., -0.0950, -0.1219, -0.0982]),\n",
       " tensor([-0.1306, -0.0578, -0.1650,  ..., -0.0905, -0.0000,  1.2948]),\n",
       " tensor([-0.2814,  0.6167, -0.2365,  ..., -0.2687, -0.0889, -0.2190]),\n",
       " tensor([ 0.3441, -0.2469, -0.3718,  ..., -0.2984, -0.0847, -0.1753]),\n",
       " tensor([-0.0856, -0.0212, -0.0520,  ..., -0.1745,  0.1969, -0.0569]),\n",
       " tensor([-0.1480, -0.1715, -0.3370,  ..., -0.3166, -0.1397,  0.1949]),\n",
       " tensor([-0.0713,  0.1546,  0.0442,  ..., -0.0912,  0.0542, -0.0232]),\n",
       " tensor([ 8.4535e-05,  6.8378e-02, -1.4599e-01,  ..., -2.3388e-01,\n",
       "         -9.3192e-02, -1.6686e-01]),\n",
       " tensor([ 0.0131,  0.1915, -0.0236,  ..., -0.0184, -0.3132,  0.2497]),\n",
       " tensor([-0.0933,  0.0030, -0.1511,  ..., -0.1316,  0.2393, -0.0957]),\n",
       " tensor([14.7661, -0.0000, -0.0000,  ..., 11.8498, -0.0000, 10.2411]),\n",
       " tensor([-0.1512, -0.1931, -0.3117,  ..., -0.3725, -0.0755, -0.3651]),\n",
       " tensor([-0.0434,  0.1491, -0.1009,  ..., -0.0487, -0.0993, -0.1320]),\n",
       " tensor([-0.2323, -0.3185, -0.2442,  ..., -0.1542, -0.3261,  0.3598]),\n",
       " tensor([ 0.0368, -0.1683, -0.2692,  ..., -0.3225,  0.0323, -0.0594]),\n",
       " tensor([-0.1096,  0.0027, -0.1384,  ..., -0.2741, -0.3590, -0.0950]),\n",
       " tensor([-0.1013,  0.2281, -0.2817,  ..., -0.0826, -0.0394,  0.0670]),\n",
       " tensor([17.0946, -0.3512, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1537, -0.0351,  0.0198,  ..., -0.2085, -0.1198, -0.0610]),\n",
       " tensor([ 0.2413, -0.3222, -0.3747,  ..., -0.2588, -0.3137, -0.1197]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.2789, -0.3172, -0.3749,  ..., -0.3686, -0.2568, -0.2020]),\n",
       " tensor([42.5303, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.6516, -0.3750, -0.0000,  ..., -0.0000, -0.0000, -0.3068]),\n",
       " tensor([-0.2345,  0.0631, -0.3592,  ..., -0.2001,  0.6220, -0.0742]),\n",
       " tensor([-0.0595, -0.3449, -0.1989,  ..., -0.3738, -0.0651, -0.0606]),\n",
       " tensor([ 0.0457, -0.1658, -0.3253,  ..., -0.2719, -0.1467, -0.1560]),\n",
       " tensor([ 0.1283,  0.1475,  0.0068,  ..., -0.1129,  0.2233, -0.0481]),\n",
       " tensor([2.4201, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 5.4252]),\n",
       " tensor([ 0.1686, -0.3703, -0.3624,  ..., -0.2813, -0.3269, -0.3526]),\n",
       " tensor([-0.1321, -0.3242, -0.3135,  ..., -0.3627, -0.3668, -0.1748]),\n",
       " tensor([-0.0100,  0.1790, -0.0314,  ..., -0.1999,  0.4052,  0.0800]),\n",
       " tensor([ 0.3397, -0.0716, -0.1316,  ..., -0.0000, -0.0000, -0.3544]),\n",
       " tensor([33.8795, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 59.8709]),\n",
       " tensor([-0.0000, -0.2296, -0.3383,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0710,  0.1518, -0.1354,  ..., -0.2054,  0.2083, -0.0382]),\n",
       " tensor([-0.2056, -0.2251, -0.1420,  ..., -0.1022, -0.2891, -0.2638]),\n",
       " tensor([ 0.1570, -0.0828, -0.0400,  ..., -0.2838,  0.3354,  0.0455]),\n",
       " tensor([-0.0283,  0.1681, -0.1648,  ..., -0.1587, -0.0878, -0.0971]),\n",
       " tensor([-0.1543, -0.3381, -0.3243,  ..., -0.0244,  0.7702, -0.3448]),\n",
       " tensor([ 0.0034,  0.1570, -0.0788,  ..., -0.2050,  0.5603,  0.0259]),\n",
       " tensor([-0.3622, -0.0268, -0.3299,  ..., -0.3231,  0.0357, -0.3737]),\n",
       " tensor([ 0.0054, -0.0429, -0.1500,  ..., -0.3109,  0.3806, -0.0965]),\n",
       " tensor([ 0.0781, -0.0023, -0.0971,  ..., -0.2484,  0.1929,  0.1306]),\n",
       " tensor([250.4045,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.0385, -0.1567, -0.1587,  ...,  0.0499,  0.3572, -0.0207]),\n",
       " tensor([ 0.1611, -0.0499, -0.2708,  ...,  0.2202,  0.3939, -0.3094]),\n",
       " tensor([-0.1634, -0.2201, -0.0469,  ..., -0.0000, -0.0000, -0.3737]),\n",
       " tensor([-0.1229, -0.0743, -0.1426,  ..., -0.2192,  0.5138, -0.1328]),\n",
       " tensor([-0.0303, -0.3535, -0.3645,  ..., -0.0698, -0.2546, -0.1210]),\n",
       " tensor([25.3845, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.2381,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3750, -0.0000, -0.3416,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0169, -0.1813, -0.3475,  ...,  0.0556,  0.4089, -0.1770]),\n",
       " tensor([-0.0921, -0.3748, -0.3085,  ..., -0.0660, -0.2540, -0.3637]),\n",
       " tensor([ 0.5395, -0.0833, -0.2331,  ..., -0.2004, -0.3740, -0.1486]),\n",
       " tensor([-0.1221, -0.2971, -0.2529,  ...,  0.1057, -0.3387, -0.2477]),\n",
       " tensor([ 0.3694, -0.2822, -0.3650,  ..., -0.2736, -0.1301, -0.3292]),\n",
       " tensor([ 0.1901, -0.2034, -0.1046,  ..., -0.0598,  0.1668,  0.1148]),\n",
       " tensor([-0.0962, -0.2769, -0.1543,  ..., -0.3631, -0.2189, -0.3694]),\n",
       " tensor([-0.0189, -0.0000, -0.2241,  ..., -0.0000,  0.1610,  1.9462]),\n",
       " tensor([ 0.0152, -0.3602, -0.3325,  ..., -0.1583, -0.2170,  0.0919]),\n",
       " tensor([-0.0895,  0.0174, -0.2352,  ..., -0.1128,  0.4689,  0.5738]),\n",
       " tensor([-0.3695, -0.3657, -0.1171,  ..., -0.2704, -0.3672, -0.2117]),\n",
       " tensor([-0.0347, -0.3673, -0.2469,  ..., -0.3301, -0.3718, -0.0000]),\n",
       " tensor([-0.2962, -0.2574, -0.2846,  ..., -0.3468,  0.0389, -0.3521]),\n",
       " tensor([-0.1597, -0.0220, -0.1431,  ..., -0.0859, -0.0448, -0.0523]),\n",
       " tensor([-0.0199, -0.0909, -0.3614,  ..., -0.2807, -0.2046, -0.3141]),\n",
       " tensor([-0.0512, -0.1208, -0.1555,  ..., -0.0891, -0.0851, -0.1669]),\n",
       " tensor([-0.0043, -0.2061, -0.2711,  ..., -0.3104, -0.0420,  0.1602]),\n",
       " tensor([-0.3392, -0.3429, -0.3692,  ..., -0.2307, -0.3498, -0.3196]),\n",
       " tensor([-0.1659, -0.0368,  0.0767,  ..., -0.0547,  0.5780, -0.1137]),\n",
       " tensor([-0.2163, -0.1270, -0.3327,  ..., -0.3740, -0.3713, -0.0680]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1556, -0.2778, -0.3377,  ..., -0.3730, -0.2574, -0.3155]),\n",
       " tensor([-0.0210, -0.3370, -0.2183,  ..., -0.3679, -0.2888, -0.3153]),\n",
       " tensor([ 0.7181, -0.3422, -0.0000,  ..., -0.0000, -0.3611, -0.3114]),\n",
       " tensor([-0.0855, -0.2259, -0.1960,  ..., -0.2066, -0.1261,  0.0029]),\n",
       " tensor([10.3860, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 19.3992]),\n",
       " tensor([ 0.0778, -0.2671, -0.1709,  ..., -0.3540,  0.3646,  0.1514]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.0214,  0.0693, -0.2119,  ..., -0.2141,  0.0167,  0.0479]),\n",
       " tensor([ 0.0948, -0.2935, -0.1729,  ..., -0.2527,  0.3295,  0.9247]),\n",
       " tensor([ 0.0917, -0.1395, -0.2587,  ..., -0.0210,  0.0457, -0.3453]),\n",
       " tensor([-0.1653, -0.0834, -0.2776,  ..., -0.3278, -0.1110,  0.0130]),\n",
       " tensor([5.2024, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1369, -0.1993, -0.2731,  ..., -0.3728,  0.0218,  0.0225]),\n",
       " tensor([-0.2497, -0.0606, -0.0267,  ..., -0.2852,  1.1450,  0.4412]),\n",
       " tensor([ 0.1827, -0.0526, -0.3716,  ...,  0.2507,  0.1606, -0.3737]),\n",
       " tensor([1.2219, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.2234,  0.1200, -0.3694,  ...,  0.1315, -0.0356, -0.0564]),\n",
       " tensor([-0.1884, -0.2110,  0.3593,  ..., -0.1598, -0.1336,  1.9976]),\n",
       " tensor([58.4013, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.4332, -0.3732, -0.2280,  ...,  0.0918,  0.5598, -0.2694]),\n",
       " tensor([-0.2306, -0.3652, -0.3605,  ..., -0.0000, -0.2923, -0.3685]),\n",
       " tensor([-0.0569, -0.1663, -0.1034,  ..., -0.1215, -0.2786, -0.1873]),\n",
       " tensor([-0.2465, -0.2829, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0249, -0.3693, -0.1547,  ..., -0.1927,  0.9429, -0.1084]),\n",
       " tensor([ 0.1132, -0.3185, -0.3428,  ..., -0.3750, -0.2328,  0.0754]),\n",
       " tensor([-0.0314, -0.1393, -0.2139,  ..., -0.2114,  0.0686, -0.2844]),\n",
       " tensor([ 0.1102, -0.2439, -0.0380,  ..., -0.0924,  0.2260, -0.0910]),\n",
       " tensor([ 0.7020, -0.3001, -0.3676,  ...,  0.0790, -0.3654, -0.3586]),\n",
       " tensor([-0.0000, -0.0000, -0.1245,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1144, -0.3716, -0.3376,  ..., -0.2649,  0.1811, -0.2345]),\n",
       " tensor([-0.1473,  0.1676,  0.6155,  ..., -0.3741,  1.2385,  0.4987]),\n",
       " tensor([ 0.1326,  0.0142, -0.1418,  ..., -0.3657,  0.4588,  0.5974]),\n",
       " tensor([1.8495, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1639, -0.3728, -0.3675,  ..., -0.1712, -0.1122, -0.3006]),\n",
       " tensor([-0.0189, -0.2527, -0.2849,  ..., -0.2568, -0.0580,  0.1568]),\n",
       " tensor([ 0.4529, -0.3545, -0.2059,  ..., -0.1808,  0.0307, -0.3733]),\n",
       " tensor([ 0.1862,  0.1975, -0.1231,  ..., -0.1539,  0.1262,  0.0331]),\n",
       " tensor([ 0.1786, -0.2003, -0.3425,  ..., -0.3206,  0.0097, -0.3680]),\n",
       " tensor([-0.0906, -0.2453, -0.3538,  ..., -0.2537, -0.3173, -0.2312]),\n",
       " tensor([ 0.0653, -0.1857, -0.3722,  ..., -0.0000,  1.2510, -0.3021]),\n",
       " tensor([ 0.4358,  0.0097, -0.0243,  ..., -0.3190, -0.0661, -0.2459]),\n",
       " tensor([ 0.0289, -0.0966, -0.3022,  ..., -0.3736,  0.2749, -0.0181]),\n",
       " tensor([-0.0149,  0.0674, -0.1871,  ..., -0.0154,  0.4883,  0.0696]),\n",
       " tensor([13.4542, -0.0000, -0.0000,  ..., 19.9372, -0.0000, -0.0000]),\n",
       " tensor([-0.2164, -0.0190, -0.2906,  ..., -0.3243, -0.3696, -0.3707]),\n",
       " tensor([-0.0133,  0.0809, -0.3467,  ..., -0.2206, -0.3744, -0.2413]),\n",
       " tensor([ 0.0862,  0.3349, -0.3640,  ..., -0.3716, -0.2931, -0.1617]),\n",
       " tensor([-0.2944, -0.0115, -0.1764,  ..., -0.3676, -0.1510, -0.3412]),\n",
       " tensor([-0.3748, -0.1939, -0.2264,  ..., -0.3747,  0.0141, -0.3522]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0720, -0.2561, -0.1702,  ..., -0.3577, -0.3569, -0.2550]),\n",
       " tensor([ 0.1615,  0.0948,  0.2547,  ..., -0.2312, -0.2233, -0.1278]),\n",
       " tensor([-0.0216, -0.0264, -0.0857,  ..., -0.1376,  0.2719, -0.0268]),\n",
       " tensor([ 0.0249, -0.2413, -0.3084,  ..., -0.2321, -0.3261,  0.0469]),\n",
       " tensor([-0.0111, -0.2345, -0.2392,  ..., -0.2400, -0.0379, -0.1301]),\n",
       " tensor([-0.0749, -0.2105, -0.1610,  ..., -0.1104,  0.0855, -0.2018]),\n",
       " tensor([250.9952,  -0.0000, 100.2178,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([38.0123, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 1.5903, -0.0000, -0.3046,  ..., -0.0000, -0.0000, -0.3413]),\n",
       " tensor([ 0.0505, -0.2204, -0.3311,  ..., -0.2711, -0.0184, -0.0917]),\n",
       " tensor([-0.0593,  0.3520, -0.1657,  ..., -0.1536,  0.0036, -0.0177]),\n",
       " tensor([-0.0274, -0.1109, -0.2125,  ..., -0.2907, -0.0181, -0.0020]),\n",
       " tensor([ 0.3106, -0.2474,  0.3731,  ..., -0.3750,  0.3716, -0.1885]),\n",
       " tensor([-0.1385, -0.1447, -0.1988,  ..., -0.1118, -0.0611, -0.2472]),\n",
       " tensor([ 0.0695, -0.1341, -0.2743,  ..., -0.2552, -0.2102, -0.2534]),\n",
       " tensor([-0.0706, -0.2411, -0.1865,  ..., -0.1366, -0.0434, -0.0851]),\n",
       " tensor([-0.0455, -0.1712, -0.3274,  ..., -0.2600, -0.2477, -0.2017]),\n",
       " tensor([-0.3732, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.2155]),\n",
       " tensor([-0.1792, -0.0430, -0.1219,  ..., -0.0393, -0.0064,  0.0189]),\n",
       " tensor([-0.1574, -0.0000,  1.3118,  ..., -0.1498, -0.2681, -0.3719]),\n",
       " tensor([-0.0854, -0.2852, -0.0398,  ..., -0.0197, -0.0860, -0.0567]),\n",
       " tensor([-0.0433,  0.0031, -0.2971,  ..., -0.1605, -0.2224, -0.2501]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., 14.5715, -0.0000, -0.0000]),\n",
       " tensor([-0.3704, -0.3382, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.2204, -0.3231, -0.1937,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0348,  0.1119, -0.0925,  ..., -0.2279,  0.3921, -0.1124]),\n",
       " tensor([-0.1257,  0.3347, -0.3177,  ..., -0.0000, -0.0000, -0.3750]),\n",
       " tensor([-0.0748,  0.0089, -0.3504,  ..., -0.1074, -0.3419, -0.2911]),\n",
       " tensor([-0.0000, -0.1284, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0731,  0.1030, -0.3471,  ..., -0.1770,  0.2924, -0.2402]),\n",
       " tensor([ 0.0645, -0.0000, -0.0900,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0237, -0.3728, -0.3259,  ..., -0.3397, -0.3535, -0.2503]),\n",
       " tensor([924.5793,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 910.4872]),\n",
       " tensor([-0.2598, -0.0085, -0.3193,  ..., -0.3157, -0.2911, -0.0943]),\n",
       " tensor([-0.0928, -0.2180, -0.1552,  ..., -0.3644, -0.1937, -0.1700]),\n",
       " tensor([-0.1281, -0.1077, -0.2654,  ..., -0.1565,  0.0406, -0.0291]),\n",
       " tensor([ 0.2177, -0.1401, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0108, -0.1656, -0.1282,  ..., -0.1992,  0.0177, -0.1377]),\n",
       " tensor([-0.0616,  0.1958, -0.1850,  ..., -0.2597, -0.0806, -0.0440]),\n",
       " tensor([ 0.2971, -0.1291,  0.1587,  ..., -0.3586, -0.1029, -0.3563]),\n",
       " tensor([ 0.0313, -0.3699, -0.3078,  ..., -0.3133, -0.3195, -0.3433]),\n",
       " tensor([ 0.0250,  0.0625, -0.3654,  ..., -0.3286, -0.2520, -0.3742]),\n",
       " tensor([-0.2253,  0.1068, -0.3498,  ...,  0.2337,  0.0749, -0.1644]),\n",
       " tensor([-0.0436, -0.0636, -0.3214,  ...,  0.1572, -0.2465, -0.3360]),\n",
       " tensor([ 0.1738, -0.1236, -0.0000,  ..., -0.3672, -0.3747, -0.3707]),\n",
       " tensor([ 0.0932,  0.0691, -0.2261,  ..., -0.3583, -0.3746, -0.2594]),\n",
       " tensor([ 0.1489, -0.1051, -0.0133,  ...,  0.0562, -0.1134, -0.0672]),\n",
       " tensor([-0.0503,  0.0205, -0.2841,  ..., -0.1396,  0.4501,  0.1820]),\n",
       " tensor([ 0.0903, -0.0703, -0.1377,  ..., -0.1792, -0.0676, -0.2317]),\n",
       " tensor([ 0.1626, -0.1820, -0.3555,  ..., -0.0932, -0.3230, -0.2959]),\n",
       " tensor([ 0.1453,  0.0312,  0.0132,  ..., -0.2977, -0.1349,  0.2155]),\n",
       " tensor([-0.1183, -0.1075, -0.1914,  ..., -0.2738,  0.1355,  0.1587]),\n",
       " tensor([-0.1945, -0.3407, -0.2358,  ..., -0.1603, -0.0000, -0.3030]),\n",
       " tensor([-0.1667,  0.4412, -0.3666,  ..., -0.3533, -0.3101, -0.3095]),\n",
       " tensor([8.0903, -0.0000, 0.1781,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([389.4640,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 0.0012,  0.1847, -0.3258,  ..., -0.0613, -0.3654, -0.2786]),\n",
       " tensor([ 0.1261, -0.2438, -0.3469,  ..., -0.3191, -0.2020, -0.1176]),\n",
       " tensor([-0.0715, -0.0490, -0.2546,  ..., -0.1909,  0.3289, -0.0966]),\n",
       " tensor([-0.0573, -0.1581, -0.1394,  ..., -0.1728, -0.3664, -0.1878]),\n",
       " tensor([-0.0799, -0.0828, -0.3463,  ..., -0.1660,  0.0115,  0.2108]),\n",
       " tensor([-0.3604, -0.0000, -0.0000,  ...,  0.2917, -0.1887, -0.0000]),\n",
       " tensor([ 0.1285,  0.0871, -0.0536,  ..., -0.1860, -0.2330, -0.3211]),\n",
       " tensor([ 0.2227, -0.1899, -0.2094,  ..., -0.2720, -0.1834, -0.0598]),\n",
       " tensor([-0.0514, -0.1062, -0.2345,  ..., -0.3636, -0.3276, -0.3732]),\n",
       " tensor([ 0.0267, -0.1387, -0.1702,  ..., -0.2434, -0.0928, -0.1746]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0149, -0.2003, -0.3435,  ..., -0.1261,  0.0225, -0.1504]),\n",
       " tensor([ 7.6860e-05,  7.1178e-02, -3.1996e-01,  ..., -2.4307e-01,\n",
       "         -3.5568e-01, -3.1264e-01]),\n",
       " tensor([-0.1304, -0.0072, -0.3459,  ..., -0.2833,  0.0554, -0.0666]),\n",
       " tensor([-0.0158, -0.0027, -0.2290,  ..., -0.1440,  0.0448, -0.0291]),\n",
       " tensor([ 0.0592,  0.2379, -0.0457,  ...,  0.0469, -0.2537,  0.0567]),\n",
       " tensor([-0.1269,  0.0205, -0.3281,  ..., -0.2664,  0.0725, -0.0092]),\n",
       " tensor([-0.0288, -0.2124, -0.3616,  ..., -0.2528, -0.3266, -0.2457]),\n",
       " tensor([-0.1079, -0.0901, -0.2965,  ..., -0.3052, -0.3005, -0.1820]),\n",
       " tensor([-0.0114, -0.1493, -0.2253,  ..., -0.1482, -0.3745, -0.2257]),\n",
       " tensor([ 0.6144,  1.3107, -0.1166,  ..., -0.0683,  0.1186,  0.0431]),\n",
       " tensor([-0.0581, -0.1139, -0.0197,  ..., -0.1278, -0.0541,  0.0426]),\n",
       " tensor([-0.1094,  0.0715, -0.3716,  ..., -0.2047,  0.0666, -0.1056]),\n",
       " tensor([ 0.2287, -0.1200, -0.2064,  ..., -0.3270, -0.3639, -0.3136]),\n",
       " tensor([0.5238, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0451,  0.0169, -0.3561,  ..., -0.2260, -0.0964, -0.1807]),\n",
       " tensor([ 0.0419,  0.0208, -0.2230,  ..., -0.3185,  0.2471,  0.1571]),\n",
       " tensor([-0.0140, -0.3683, -0.3734,  ..., -0.0798, -0.0000, -0.3345]),\n",
       " tensor([-0.1416, -0.2627, -0.3735,  ..., -0.0345, -0.2453, -0.3153]),\n",
       " tensor([ 0.0309, -0.0550, -0.1928,  ..., -0.2645, -0.0600, -0.1030]),\n",
       " tensor([-0.3267,  0.0394, -0.1533,  ..., -0.1505, -0.1939, -0.2562]),\n",
       " tensor([-0.1165, -0.1177, -0.2164,  ..., -0.1479, -0.0470, -0.1185]),\n",
       " tensor([ 0.0131, -0.3665, -0.0928,  ...,  0.1752,  0.5007, -0.2161]),\n",
       " tensor([-0.1062, -0.0624, -0.3476,  ..., -0.2900, -0.2722, -0.1003]),\n",
       " tensor([ 0.0327,  0.2127, -0.3291,  ..., -0.0818,  0.0957, -0.3530]),\n",
       " tensor([-0.0974, -0.2415, -0.1781,  ...,  0.0071, -0.3119, -0.3015]),\n",
       " tensor([-0.1470, -0.3011, -0.0984,  ..., -0.3438, -0.3433, -0.1365]),\n",
       " tensor([-0.0330, -0.2559, -0.1639,  ..., -0.0087,  0.0871, -0.3511]),\n",
       " tensor([  -0.0000,   -0.0000, 1545.1482,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0.1113, -0.1149, -0.2885,  ..., -0.2330,  0.8635,  0.7631]),\n",
       " tensor([ 425.8314,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1126.5038]),\n",
       " tensor([21.2295, -0.0000, 30.6834,  ..., -0.0000, -0.0000, 14.4260]),\n",
       " tensor([220.7330,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([277.0028,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([27.5189, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 567167.3750, 1655982.5000,  217646.1875,  ...,      -0.0000,\n",
       "              -0.0000, 1500526.3750]),\n",
       " tensor([35.8205, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 40.9689,  -0.0000,  13.1272,  ...,  -0.0000,  -0.0000, 186.3212]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([138.1054,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([1155.7209,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         2359.3472]),\n",
       " tensor([10012.8633,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "          2554.1260]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([423.9754,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 560.5159]),\n",
       " tensor([44.3219, -0.0000, -0.0553,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([8004.5093,   -0.0000, 1960.7693,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([ 58.0126, 103.1400,  46.0231,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([57437.9961,    -0.0000, 24111.5684,  ...,    -0.0000,    -0.0000,\n",
       "         34875.0547]),\n",
       " tensor([-0.0000, -0.0000, -0.3269,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0894,  0.1378, -0.2950,  ..., -0.1560, -0.2567, -0.3107]),\n",
       " tensor([21.9397, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 63.5991]),\n",
       " tensor([29.4436, -0.0000, 60.6466,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.3483, -0.3742,  0.0656,  ...,  0.1689, -0.2692, -0.2845]),\n",
       " tensor([-0.1663, -0.0000, -0.1687,  ..., -0.0000, -0.0000, -0.1955]),\n",
       " tensor([-0.1046, -0.0594, -0.0965,  ..., -0.1408,  0.1287, -0.1340]),\n",
       " tensor([-0.3261, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([  -0.0000, 1962.7908,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([5454.8916,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([21621.7227,    -0.0000, 13474.8154,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([14.9344, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0935, -0.0000,  5.3547,  ..., -0.0000, -0.0000, -0.3620]),\n",
       " tensor([134.8036,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([6433.0928,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         4441.8838]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 91.1202,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 122.0654]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([517.6890,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 265.7051]),\n",
       " tensor([ 6.1050, -0.0000, -0.1975,  ...,  7.7806,  0.1475, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([150.4796,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 12.8111,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 566.8519]),\n",
       " tensor([205.5544,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([6882.1982,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([82.8386, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 47.2697]),\n",
       " tensor([5.6645, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([505.8078,  -0.0000,  19.2398,  ...,  -0.0000,  -0.0000,  88.2339]),\n",
       " tensor([-0.0000, -0.0000, -0.3294,  ..., -0.0000, -0.0000, -0.2858]),\n",
       " tensor([37.4991, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 8.2696, -0.0000, -0.1110,  ..., -0.0000, -0.0000,  4.1537]),\n",
       " tensor([ 4.8223e+02, -0.0000e+00, -2.3611e-01,  ..., -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00]),\n",
       " tensor([-0.0193, -0.0000, -0.0000,  ..., -0.3739, -0.0000, -0.3615]),\n",
       " tensor([68.7968, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.2023]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1066, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3716]),\n",
       " tensor([16.1429, -0.0000, 15.0785,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0000, -0.0000, 78.0901,  ..., 52.1190, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([   -0.0000,    -0.0000,  1633.9730,  ...,    -0.0000,    -0.0000,\n",
       "         12229.3184]),\n",
       " tensor([106.1569,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 239.2498]),\n",
       " tensor([35645.1719,    -0.0000, 17906.8398,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.3471,  ..., 16.9016, -0.0000, -0.0000]),\n",
       " tensor([-0.3694, -0.0000, 39.7469,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([1.6658, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([50.8164, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.1095, -0.1515, -0.2949,  ..., -0.1070, -0.1105, -0.1463]),\n",
       " tensor([-0.0660,  0.4150, -0.0537,  ..., -0.1295,  0.4583, -0.2207]),\n",
       " tensor([71.1702, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([6.2294, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([647.4515,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 509.8525]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([117.8876,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 77.3260,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 553.9769]),\n",
       " tensor([137.9745,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([49.2275, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2893, -0.3341,  0.0093,  ...,  0.3401, -0.2465, -0.2578]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.0292, -0.3704, -0.2262,  ..., -0.0000, -0.0000, -0.3216]),\n",
       " tensor([ -0.0000, 158.3785,  25.9844,  ...,  -0.0000,  -0.0000, 689.0500]),\n",
       " tensor([893.0236,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.3605, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([5.4470, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([13.3272, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([300.1290, 432.3632, 507.4823,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([20.6881, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([7.6078, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 9.3026]),\n",
       " tensor([900.6158,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 567.3915]),\n",
       " tensor([-0.0000, -0.0000, -0.1891,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([5.2236, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([9500.6816,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         3842.8198]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([1618.3452,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "          846.7131]),\n",
       " tensor([3.4728, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 608.1603,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1180.5530]),\n",
       " tensor([14385.1699,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "          9666.8516]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([6184.0835,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         3511.1375]),\n",
       " tensor([-0.0000, -0.0000, -0.2485,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([  -0.0000,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         3211.7749]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([279.0111,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([  -0.0000,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         7794.0205]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([2267.4165,  263.2391,   -0.0000,  ...,  654.3263,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([2.0100e-01, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00, -0.0000e+00,\n",
       "         2.6651e+02]),\n",
       " tensor([4.3463, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0920,  0.7923, -0.1675,  ..., -0.0000,  0.4110, -0.1065]),\n",
       " tensor([1424.5642,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([45294.2109,    -0.0000, 22010.8047,  ...,    -0.0000,    -0.0000,\n",
       "         55818.4492]),\n",
       " tensor([15.5986, -0.0000,  5.2087,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([11837.3896,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         19919.4023]),\n",
       " tensor([2814.8406,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1574.4418]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ -0.0000,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 193.2283]),\n",
       " tensor([17985.4531,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([4597.1826,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "          288.4012]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([262.2112,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 318.0090]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([428.4664,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 818.7548]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([3141.2009,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         5117.3232]),\n",
       " tensor([7531.4844,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         2780.5796]),\n",
       " tensor([118630.3984,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
       "             -0.0000,  63145.2461]),\n",
       " tensor([ 0.7202,  1.0770, -0.0617,  ..., -0.3741,  1.1383, -0.3748]),\n",
       " tensor([19.0156, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 22.9810]),\n",
       " tensor([10878.0918,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         31522.6211]),\n",
       " tensor([127.2996,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 149.4936]),\n",
       " tensor([5360.8711,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         8037.8921]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([101.6340,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 835.7136]),\n",
       " tensor([68500.8281,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         28239.9277]),\n",
       " tensor([ 0.9713, -0.2659, -0.2408,  ..., -0.2711, -0.3217, -0.3186]),\n",
       " tensor([3.7952, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([145538.5312,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
       "             -0.0000,     -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ -0.0000,  -0.0000, 212.1749,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 30.9151, 133.7394,  -0.0000,  ...,  -0.0000,  -0.0000, 733.3387]),\n",
       " tensor([0.2196, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3743, -0.0000, -0.0447,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([1710.7625,   -0.0000,  352.8822,  ...,   -0.0000,   -0.0000,\n",
       "         1886.6663]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([  -0.0000,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1021.9852]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([  -0.0000,  220.4922,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         3360.7957]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([414.7650,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 8642.2871,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         26260.0391]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 46.9456]),\n",
       " tensor([   -0.0000,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         14334.7568]),\n",
       " tensor([ 5.5170, -0.0000, -0.3460,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3044, -0.0000,  2.6923,  ..., -0.0000, -0.0000, -0.2608]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([339.1100,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 100.9991]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([372744.1250,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
       "             -0.0000,     -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 8948.7363,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         11170.6396]),\n",
       " tensor([  -0.0000,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         7107.5327]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([326.6772,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 709.1233]),\n",
       " tensor([155.2170,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  61.4011]),\n",
       " tensor([-0.1650,  1.0002, -0.0000,  ..., -0.0000, -0.1377, -0.0000]),\n",
       " tensor([0.2309, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([84594.3906,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([9011.5098,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         4288.6416]),\n",
       " tensor([13653.1279,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0541, -0.0000, -0.2938,  ..., -0.0000, -0.0000, -0.1700]),\n",
       " tensor([103.0973,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([111.8700,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 240.2401]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([5.1204, -0.0000, 7.1992,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([20.0579, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([1067.5881,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([28.8782, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0388,  0.0976, -0.1282,  ..., -0.2937, -0.2518, -0.0282]),\n",
       " tensor([15.0035, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.2361, -0.3567, -0.3661,  ..., -0.3648, -0.3750, -0.3526]),\n",
       " tensor([8.1536, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([3656.0835,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1723.1459]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([5.3533, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([107363.1172,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
       "             -0.0000, 109814.7734]),\n",
       " tensor([11.2835, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 2.0679e+01, -0.0000e+00,  9.0872e+00,  ...,  1.9275e+01,\n",
       "         -0.0000e+00, -1.0710e-02]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1179, -0.0551, -0.0853,  ..., -0.1064, -0.3158, -0.1857]),\n",
       " tensor([ 0.0042,  0.2418, -0.1161,  ..., -0.1892,  0.1060, -0.2302]),\n",
       " tensor([86.2594, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 25.8369]),\n",
       " tensor([11.3481, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0935, -0.2460, -0.0567,  ..., -0.3448,  0.5275, -0.2543]),\n",
       " tensor([-0.3006, -0.3303, -0.2079,  ...,  0.1414, -0.0741, -0.2287]),\n",
       " tensor([17.2671, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.9246]),\n",
       " tensor([-0.0000, -0.0000, 46.1341,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2479,  0.2718,  0.2767,  ..., -0.0974, -0.0118, -0.2652]),\n",
       " tensor([ 0.0947, -0.2966, -0.3491,  ..., -0.3150, -0.0000, -0.3678]),\n",
       " tensor([ 0.1149, -0.0185, -0.1891,  ..., -0.1362, -0.0784, -0.0810]),\n",
       " tensor([-0.3354, -0.3538, -0.3502,  ..., -0.1639, -0.2863, -0.3717]),\n",
       " tensor([285.2723,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  38.0212]),\n",
       " tensor([-0.1179, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([84.6656, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0456, -0.1252, -0.3528,  ..., -0.2769, -0.2879, -0.3391]),\n",
       " tensor([-0.1159, -0.0000, -0.3693,  ..., -0.0826, -0.0000, -0.0000]),\n",
       " tensor([-0.1820, -0.1887, -0.2541,  ..., -0.2448, -0.2648, -0.2080]),\n",
       " tensor([ 0.0432, -0.2318, -0.3749,  ..., -0.1138, -0.2328, -0.2578]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0000, -0.0000, 4.3043,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([18.9049, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2295, -0.0000, -0.1222,  ...,  0.0759, -0.3581, -0.2998]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([7.5185, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([139.9178,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.0000, -0.0000, 73.2990,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([1.8476, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([31.5292, -0.0000, 30.2693,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([28.0788, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([141.5161,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([25.5417, -0.0000, 34.7987,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0956, -0.3618, -0.3124,  ..., -0.2619, -0.3619, -0.1766]),\n",
       " tensor([-5.1629e-02, -4.0548e-02, -6.8030e-04,  ..., -2.5457e-02,\n",
       "          1.7306e-04, -2.5480e-01]),\n",
       " tensor([ 1.5598, -0.0766, -0.2294,  ..., -0.3531,  0.3206, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([31.3539, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3404, -0.0000,  0.0283,  ..., -0.0250, -0.0000, -0.0000]),\n",
       " tensor([-0.3635, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3709]),\n",
       " tensor([-0.0000, -0.0000, 24.5464,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1284, -0.2073, -0.3602,  ..., -0.1815, -0.1657, -0.3178]),\n",
       " tensor([611.4379,  -0.0000, 898.1310,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.0669,  0.2252, -0.1312,  ..., -0.2066, -0.3410, -0.3723]),\n",
       " tensor([-0.3742, -0.0000, -0.0754,  ..., -0.0000, -0.0000, -0.2003]),\n",
       " tensor([11.0003, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0091, -0.0731, -0.3170,  ..., -0.1534, -0.2436, -0.1745]),\n",
       " tensor([199.6189,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.2681,  0.0784, -0.0000,  ..., -0.1234, -0.3529, -0.3748]),\n",
       " tensor([ -0.0000,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 412.2158]),\n",
       " tensor([-0.2984, -0.0000,  3.2225,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0144, -0.1586, -0.2246,  ..., -0.0548, -0.2752, -0.1438]),\n",
       " tensor([-0.2570, -0.3625, -0.2554,  ...,  0.0149, -0.2253, -0.3611]),\n",
       " tensor([ 0.0085,  0.2829, -0.0288,  ..., -0.0777,  0.0504, -0.2306]),\n",
       " tensor([135.7484,  -0.0000, 102.7527,  ...,  -0.0000,  -0.0000,  41.9007]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([58.0678, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3564, -0.2544, -0.3602,  ..., -0.3544, -0.0000, -0.3747]),\n",
       " tensor([ 0.0551, -0.3079, -0.0952,  ...,  1.0306,  0.0191, -0.3632]),\n",
       " tensor([-0.3608, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3105]),\n",
       " tensor([5.1791, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([20.7434, -0.0000, 21.8526,  ..., 44.5421, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 26.4167,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 136.7245]),\n",
       " tensor([-0.3741, -0.0000, -0.0000,  ...,  1.2596, -0.0000, -0.0000]),\n",
       " tensor([-0.0640, -0.0968, -0.2934,  ...,  0.0583, -0.3282, -0.1137]),\n",
       " tensor([ 0.0357,  0.2250, -0.1364,  ..., -0.1214, -0.2345, -0.0812]),\n",
       " tensor([-0.0602, -0.3497, -0.3643,  ..., -0.2689, -0.3750, -0.3658]),\n",
       " tensor([ 0.5904, -0.2032, -0.0000,  ...,  1.4937, -0.0000, -0.0376]),\n",
       " tensor([-0.0103, -0.1626, -0.2951,  ...,  0.0841, -0.3706, -0.3006]),\n",
       " tensor([ 1.4416,  0.2924, -0.3545,  ...,  0.1494, -0.3690, -0.0000]),\n",
       " tensor([-0.0822,  0.4294, -0.3459,  ..., -0.2311, -0.2025, -0.0508]),\n",
       " tensor([12.3529, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 21.6232]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([2.8786, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 8.9378, -0.0000, -0.2419,  ..., -0.0000, -0.0000,  6.6438]),\n",
       " tensor([-0.2215, -0.2638, -0.0000,  ...,  0.0368, -0.3198, -0.1640]),\n",
       " tensor([ 0.2756, -0.0000, -0.0000,  ..., -0.1943, -0.3554, -0.3142]),\n",
       " tensor([-0.2936,  0.8222, -0.3282,  ..., -0.0000, -0.3187, -0.3750]),\n",
       " tensor([ 0.1035,  0.0421, -0.1670,  ..., -0.1137,  0.2074, -0.1212]),\n",
       " tensor([-0.2570,  0.1575, -0.3311,  ..., -0.2652, -0.1987, -0.1625]),\n",
       " tensor([-0.0405,  1.5838, -0.2156,  ..., -0.0000, -0.0996, -0.0000]),\n",
       " tensor([37.9863, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.0484, -0.1079, -0.1889,  ..., -0.2226,  0.4879, -0.1753]),\n",
       " tensor([24.9277, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([2441.6121,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         2036.7015]),\n",
       " tensor([-0.2248, -0.1685, -0.1557,  ..., -0.3336, -0.0000, -0.1603]),\n",
       " tensor([-0.0497, -0.1231, -0.0848,  ..., -0.0410,  0.3017, -0.1293]),\n",
       " tensor([3.3913, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([12.3954, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 67.9310]),\n",
       " tensor([-0.1363, -0.3148, -0.3567,  ..., -0.3590,  0.0185, -0.3043]),\n",
       " tensor([-0.2760, -0.2826, -0.2723,  ..., -0.2388, -0.1716, -0.2587]),\n",
       " tensor([ 0.0449, -0.1027, -0.0939,  ..., -0.3101,  0.8944, -0.2586]),\n",
       " tensor([ 0.7984, -0.2841, -0.0000,  ..., -0.3735, -0.1738, -0.1830]),\n",
       " tensor([-0.0000, -0.0000, -0.3018,  ..., -0.1700, -0.0000, -0.1693]),\n",
       " tensor([-0.0666, -0.2411, -0.3299,  ..., -0.3714, -0.3735, -0.0000]),\n",
       " tensor([-0.1284, -0.1109, -0.0766,  ..., -0.0837, -0.0817, -0.1780]),\n",
       " tensor([-0.0935,  0.0261, -0.2734,  ..., -0.2375,  0.0485, -0.3750]),\n",
       " tensor([487.8769,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.2907, -0.0034,  0.4592,  ..., -0.0481, -0.2545, -0.2961]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0622,  0.2446, -0.3219,  ..., -0.3397, -0.1091, -0.3331]),\n",
       " tensor([ 0.1607, -0.3174, -0.3357,  ..., -0.0244,  0.3649, -0.3313]),\n",
       " tensor([-0.1660,  0.1340, -0.0017,  ..., -0.2990, -0.0520, -0.1548]),\n",
       " tensor([ 7.4575, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 12.8172]),\n",
       " tensor([245.3412,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  52.1444]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([9.0792, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0241, -0.2300, -0.0000,  ..., -0.2028, -0.2871,  0.7215]),\n",
       " tensor([ 0.1550, -0.0000, -0.1903,  ..., -0.3675,  0.0881, -0.2965]),\n",
       " tensor([ 0.2653,  0.0160, -0.3723,  ..., -0.2936,  0.1532, -0.3211]),\n",
       " tensor([-0.0401, -0.0812, -0.3663,  ...,  0.1164, -0.3649,  0.4505]),\n",
       " tensor([-0.2786,  0.3979, -0.2870,  ..., -0.2833,  0.3207, -0.0590]),\n",
       " tensor([20.4710, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 11.7191]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1605, -0.3596, -0.3747,  ..., -0.3132, -0.3733, -0.3583]),\n",
       " tensor([-0.3420, -0.0000, -0.2387,  ..., -0.2083, -0.0000, -0.3297]),\n",
       " tensor([49.6224, -0.0000,  5.5806,  ..., -0.0000, -0.0000,  1.9294]),\n",
       " tensor([-0.2493, -0.0000,  0.7737,  ..., -0.3749, -0.0000, -0.0586]),\n",
       " tensor([ 1.1528, -0.3658, -0.3745,  ..., -0.3599, -0.2250,  1.0224]),\n",
       " tensor([ 1.6841, -0.0000, -0.0000,  ...,  0.9482, -0.0000, -0.3546]),\n",
       " tensor([-0.2740,  0.6609, -0.3531,  ..., -0.3641, -0.3745, -0.0044]),\n",
       " tensor([-0.1105, -0.3590,  0.2075,  ..., -0.3673, -0.2415,  0.2678]),\n",
       " tensor([-0.0327, -0.3712, -0.1138,  ..., -0.2760, -0.1801, -0.3619]),\n",
       " tensor([ 0.1114, -0.0034, -0.3742,  ..., -0.2949,  0.2673, -0.0731]),\n",
       " tensor([-0.3407, -0.3745, -0.1313,  ...,  0.0285, -0.1959, -0.1966]),\n",
       " tensor([ 1.0608, -0.2900, -0.3687,  ..., -0.2302, -0.2381,  0.2189]),\n",
       " tensor([-0.3495, -0.2681, -0.3674,  ...,  0.1655, -0.3750, -0.3477]),\n",
       " tensor([ 7.4598, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 19.1716]),\n",
       " tensor([-0.1894,  0.0073, -0.1460,  ..., -0.2021, -0.1719, -0.1305]),\n",
       " tensor([ 0.0954, -0.2880, -0.3065,  ..., -0.0926, -0.3245,  0.3659]),\n",
       " tensor([-0.3041, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2262, -0.3536, -0.2846,  ..., -0.3236, -0.3031, -0.3590]),\n",
       " tensor([-0.2654, -0.3731, -0.1916,  ..., -0.1562, -0.3081, -0.3704]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.2869, -0.2099, -0.3096,  ..., -0.3300, -0.2630, -0.1791]),\n",
       " tensor([ 0.0540, -0.1984, -0.0893,  ..., -0.1264, -0.0379, -0.0191]),\n",
       " tensor([-0.0123, -0.3127, -0.3419,  ..., -0.0204, -0.0000, -0.1426]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.2372,  0.0452, -0.2732,  ..., -0.3733, -0.3745, -0.3733]),\n",
       " tensor([ 1.3738, -0.3610, -0.3603,  ..., -0.2835, -0.3738, -0.1449]),\n",
       " tensor([ 0.0722, -0.1853, -0.3695,  ..., -0.3653, -0.3564, -0.1505]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([540.7155,  -0.0000,  -0.0000,  ..., 715.8444,  -0.0000,  19.3896]),\n",
       " tensor([-0.3395, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1594, -0.1468, -0.2681,  ..., -0.3611, -0.3660, -0.2054]),\n",
       " tensor([-0.2233, -0.3083, -0.2136,  ..., -0.3727, -0.3145, -0.2537]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.3458, -0.0000, -0.0000]),\n",
       " tensor([-0.2570, -0.2605, -0.3717,  ..., -0.3288, -0.3525, -0.3746]),\n",
       " tensor([-0.1367, -0.3078, -0.3594,  ..., -0.3748, -0.3747, -0.2755]),\n",
       " tensor([ 1.5094, -0.0000, -0.3745,  ..., -0.0000, -0.0000,  4.6628]),\n",
       " tensor([-0.2218,  0.1296, -0.2694,  ..., -0.2772, -0.0099, -0.3554]),\n",
       " tensor([-0.1896, -0.3386, -0.3406,  ..., -0.1760, -0.2174, -0.3241]),\n",
       " tensor([ 0.6398, -0.0000,  0.4536,  ...,  1.4061, -0.3050, -0.3136]),\n",
       " tensor([31.2604, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  5.7358]),\n",
       " tensor([-0.3750, -0.3032, -0.3131,  ..., -0.3575, -0.3332, -0.2731]),\n",
       " tensor([ 0.0237, -0.0845, -0.0823,  ..., -0.0711, -0.2215, -0.2149]),\n",
       " tensor([-0.0743,  0.0627, -0.1073,  ..., -0.0012,  0.0724, -0.3289]),\n",
       " tensor([-0.1955, -0.0392, -0.1818,  ..., -0.2740,  0.1526, -0.2643]),\n",
       " tensor([ 0.1343,  0.2158, -0.3720,  ..., -0.1701, -0.2003, -0.1384]),\n",
       " tensor([-0.2689, -0.3738, -0.3727,  ..., -0.3346, -0.3591, -0.3672]),\n",
       " tensor([ 0.3238,  0.4666, -0.2029,  ..., -0.3686, -0.2289,  0.1491]),\n",
       " tensor([-0.3084, -0.3662,  0.9680,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.0214, -0.3745, -0.3533,  ...,  0.0309, -0.3660, -0.3721]),\n",
       " tensor([-0.2323, -0.1857, -0.1012,  ..., -0.3433, -0.2741, -0.0249]),\n",
       " tensor([-0.3110, -0.3708, -0.1872,  ..., -0.2816, -0.1298,  0.9398]),\n",
       " tensor([ 0.0342, -0.3294, -0.3750,  ..., -0.0136, -0.3468, -0.1236]),\n",
       " tensor([15.7820, -0.0000, 16.8305,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1473, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  1.5842]),\n",
       " tensor([13.0751, -0.0000, -0.0000,  ..., -0.0000,  4.0384, -0.2149]),\n",
       " tensor([-0.0032, -0.0346, -0.3744,  ..., -0.2798, -0.1757, -0.3097]),\n",
       " tensor([ 0.1772, -0.2742, -0.2609,  ...,  0.0574, -0.2466, -0.3072]),\n",
       " tensor([-0.0256, -0.3196, -0.3577,  ..., -0.3685, -0.0000, -0.2227]),\n",
       " tensor([675.8159,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.0000, 1.7229, -0.0000,  ..., -0.0000, -0.0000, 1.0224]),\n",
       " tensor([-0.0501, -0.1202, -0.3144,  ..., -0.2211, -0.2241, -0.2411]),\n",
       " tensor([-0.0000, -0.0000, 9.8535,  ..., -0.0000, -0.0000, 0.7220]),\n",
       " tensor([4.6261, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([541.5902,  -0.0000,  83.5459,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 3.2484e+02, -0.0000e+00, -2.5385e-01,  ..., -0.0000e+00,\n",
       "         -0.0000e+00,  3.2655e+02]),\n",
       " tensor([2981.2471,   -0.0000,  735.1239,  ...,   -0.0000,   -0.0000,\n",
       "         1501.6038]),\n",
       " tensor([142.5123,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([2509.9243,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([1346.6833,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([60.6428, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 21.2995]),\n",
       " tensor([-0.2517, -0.0308, -0.2724,  ..., -0.0521,  0.0246, -0.2611]),\n",
       " tensor([ -0.0000, 204.7789,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([39.5969, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 65.6127]),\n",
       " tensor([30.8166, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0754,  0.4534, -0.3510,  ..., -0.2222, -0.3286,  0.5861]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 3.0015]),\n",
       " tensor([280.7316,  -0.0000, 397.9052,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([18934.4902,    -0.0000, 12412.5078,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([-0.0191, -0.3747, -0.2790,  ..., -0.3668, -0.2647, -0.2819]),\n",
       " tensor([ 7.1957,  6.5687, -0.0000,  ..., -0.0000, -0.0000, 26.4422]),\n",
       " tensor([3759.2275,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1316,  0.1043, -0.1935,  ..., -0.2091, -0.2832, -0.2177]),\n",
       " tensor([ 1.5016, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3747]),\n",
       " tensor([12.8177, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 13.0626]),\n",
       " tensor([-0.0000,  3.4952,  0.7913,  ...,  1.1635, -0.2400, -0.0000]),\n",
       " tensor([4753.1792,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0.2468, -0.0540, -0.3510,  ..., -0.0000, -0.0000, -0.3311]),\n",
       " tensor([ 0.7627, -0.3309,  0.1095,  ..., -0.0269, -0.2509,  0.1363]),\n",
       " tensor([4.9481, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 0.0616, -0.2971,  0.0908,  ..., -0.3529, -0.2449, -0.2029]),\n",
       " tensor([-0.0000, -0.0919, -0.2670,  ..., -0.0000, -0.0000,  3.3036]),\n",
       " tensor([ 0.0494, 15.9188, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([47.0334, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([26.2467, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0852, -0.0218, -0.2236,  ..., -0.1197,  0.1493,  0.0327]),\n",
       " tensor([33.9293, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([3418.6277,   -0.0000,  627.3916,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([ 0.0605, -0.3572, -0.2748,  ..., -0.1676, -0.1744, -0.2945]),\n",
       " tensor([-0.1641,  0.8303,  0.0823,  ..., -0.3331, -0.0000, -0.0318]),\n",
       " tensor([ 0.4292, -0.3375,  0.0427,  ..., -0.2786, -0.3426, -0.2379]),\n",
       " tensor([  -0.0000,   -0.0000, 1668.8467,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([1061.2708,  208.5205,  451.6936,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([ 5.6193,  0.9316, -0.0000,  ..., -0.0000, -0.0000, 46.8084]),\n",
       " tensor([ 2.8241, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.1768]),\n",
       " tensor([-0.0342, -0.3728, -0.2704,  ..., -0.3497, -0.0000, -0.2661]),\n",
       " tensor([1843.0140,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "          697.4938]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([4.7573, 3.2036, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.1245,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([294.8890,  -0.0000, 797.8834,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([751.0054,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 182.3581]),\n",
       " tensor([349.7284,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 175.9789]),\n",
       " tensor([ 9.0082, -0.0000,  6.5685,  ..., -0.0000, -0.0000, 56.2691]),\n",
       " tensor([-0.0823,  0.1955, -0.0582,  ...,  0.0557,  0.3886,  0.0089]),\n",
       " tensor([16823.8711,    -0.0000, 16451.6211,  ...,    -0.0000,    -0.0000,\n",
       "          3835.9854]),\n",
       " tensor([128.4549,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.3735,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([33.5949, -0.0000, -0.2948,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([56420.6211,    -0.0000, 32165.4570,  ..., 45510.5234,    -0.0000,\n",
       "         42747.0742]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3634, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3311, -0.0000, -0.2262,  ..., -0.0000, -0.0000, -0.3693]),\n",
       " tensor([ 704.4109, 4124.1240, 2873.4946,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0.2366,  2.5810, -0.0000,  ..., -0.0000, -0.2508, -0.2136]),\n",
       " tensor([47.1877, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.4145, -0.3667,  0.0113,  ..., -0.3500, -0.3210, -0.0146]),\n",
       " tensor([20160.4102,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "            -0.0000]),\n",
       " tensor([-0.0759,  0.4075, -0.0701,  ..., -0.1922,  0.0705, -0.0967]),\n",
       " tensor([174647.3125,     -0.0000, 164694.0312,  ...,     -0.0000,\n",
       "             -0.0000,     -0.0000]),\n",
       " tensor([1030.9414,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "          638.3004]),\n",
       " tensor([66.0130, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 48.2753]),\n",
       " tensor([2078.7764,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "          813.9749]),\n",
       " tensor([7.3681, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([1513.7841,   -0.0000, 1345.3796,  ...,   -0.0000,  332.9240,\n",
       "         1189.3826]),\n",
       " tensor([ 774.9626,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         6129.1787]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 823.9697,   -0.0000, 4406.6382,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([7.9727, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 61.7109,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 119.3232]),\n",
       " tensor([ 9.4384, -0.0000,  4.3835,  ..., -0.0000, -0.0000, -0.3127]),\n",
       " tensor([   -0.0000,  3195.2812,    -0.0000,  ...,    -0.0000,    -0.0000,\n",
       "         28184.2617]),\n",
       " tensor([1658.9808,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([  -0.0000,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "         1056.3259]),\n",
       " tensor([23.2166, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2574,  0.0566, -0.0000,  ..., -0.0000,  0.4549, -0.0000]),\n",
       " tensor([3694.0312,   -0.0000,   -0.0000,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0.0000, -0.0000, 61.0310,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([22.7981, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2781, -0.0000, -0.2556,  ..., -0.0847, -0.0000, -0.0000]),\n",
       " tensor([ 0.1732, -0.3743, -0.3750,  ..., -0.0000, -0.3559, -0.3734]),\n",
       " tensor([-0.0000, -0.3636, -0.0000,  ..., -0.0000, -0.2049, -0.0000]),\n",
       " tensor([-0.0342, -0.3081, -0.1026,  ..., -0.1359, -0.2407, -0.0040]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([128.6240,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([ 1.2637, -0.0000, -0.0000,  ..., -0.3356, -0.3653, -0.0000]),\n",
       " tensor([-0.0926, -0.3660, -0.3647,  ..., -0.1910,  0.0129,  0.3469]),\n",
       " tensor([18.8033, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([2.6434, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3539, -0.2107, -0.2626,  ..., -0.0000, -0.3690, -0.2724]),\n",
       " tensor([9.7379, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 1.2873, -0.0000,  0.5743,  ...,  0.0109, -0.0000, -0.3440]),\n",
       " tensor([ 0.4135, -0.3697, -0.3613,  ..., -0.3444, -0.1140, -0.2106]),\n",
       " tensor([ 6.6151, -0.3044, -0.0000,  ..., -0.1076, -0.0000, -0.0000]),\n",
       " tensor([ -0.0000,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 113.4365]),\n",
       " tensor([ -0.0000,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 116.4905]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.0000, -0.0000, 8.4825,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1330, -0.1338, -0.2065,  ..., -0.2836, -0.3619, -0.1301]),\n",
       " tensor([4570.7769,   -0.0000, 2052.1169,  ...,   -0.0000,   -0.0000,\n",
       "           -0.0000]),\n",
       " tensor([-0.2141, -0.3750, -0.3743,  ..., -0.2909, -0.3689, -0.2935]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([ 84.2036,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 237.9172]),\n",
       " tensor([244.3672,  18.7397,  -0.0000,  ...,  -0.0000,  -0.0000, 633.3837]),\n",
       " tensor([-0.3387, -0.3695,  0.1902,  ..., -0.3745, -0.3746,  0.8230]),\n",
       " tensor([31.5141, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.1766,  0.2153, -0.2646,  ..., -0.3522, -0.3718, -0.1593]),\n",
       " tensor([35.4701, -0.0000, -0.0000,  ...,  9.6073, -0.0000, -0.0000]),\n",
       " tensor([-0.3503,  0.5855, -0.3682,  ...,  0.0865, -0.2430, -0.3477]),\n",
       " tensor([-0.2215, -0.2734, -0.2648,  ..., -0.1981, -0.1483, -0.1776]),\n",
       " tensor([ 0.0448,  0.0182, -0.1668,  ..., -0.0530, -0.0357,  0.0295]),\n",
       " tensor([-0.0938,  0.1869,  0.0319,  ..., -0.0956,  0.4816, -0.0697]),\n",
       " tensor([ 0.3621, -0.1960, -0.3324,  ...,  0.1333,  0.1988,  0.0333]),\n",
       " tensor([-0.0846,  0.1512, -0.1425,  ..., -0.1285, -0.0447, -0.0995]),\n",
       " tensor([4.6143, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.0511, -0.1869, -0.3381,  ...,  0.0467, -0.3055,  0.1043]),\n",
       " tensor([6.6163, -0.0000, 8.4103,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2889, -0.3696,  0.2183,  ..., -0.0618, -0.3549, -0.2442]),\n",
       " tensor([-0.3424,  0.4379, -0.3443,  ...,  0.2037,  0.3918, -0.1784]),\n",
       " tensor([-0.2071, -0.3701, -0.3596,  ..., -0.3709, -0.3432, -0.3044]),\n",
       " tensor([0.5255, 5.6623, -0.0000,  ..., 2.6484, -0.0000, -0.0000]),\n",
       " tensor([-0.2165, 13.4890, -0.0000,  ..., -0.0000, -0.0000,  0.1184]),\n",
       " tensor([-0.1220, -0.0166, -0.1564,  ..., -0.2251,  0.0310, -0.0235]),\n",
       " tensor([-0.3696,  0.0427,  0.3682,  ..., -0.3441, -0.0947,  1.1156]),\n",
       " tensor([5.7351, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 4.6454]),\n",
       " tensor([ -0.0000,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 505.8055]),\n",
       " tensor([ 1.5984, -0.0000, -0.0000,  ..., -0.0000, -0.0063, -0.0000]),\n",
       " tensor([-0.0000, -0.0000, -0.0893,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3395,  0.1977,  0.4039,  ...,  0.7065,  0.2708,  0.1007]),\n",
       " tensor([ 0.1033, -0.2899, -0.2933,  ..., -0.3423,  0.0304, -0.3750]),\n",
       " tensor([-0.1575, -0.0874, -0.2174,  ..., -0.0321, -0.0780, -0.1351]),\n",
       " tensor([-0.0000, -0.0000, 1.3598,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([13.6129, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.6252]),\n",
       " tensor([189.7294,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,   8.0613]),\n",
       " tensor([378.2073,  -0.0000, 254.5931,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.1003,  0.2836, -0.3067,  ..., -0.3132,  0.3995, -0.1099]),\n",
       " tensor([-0.1592,  0.0613, -0.3085,  ..., -0.3633, -0.3328, -0.3702]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.1030, -0.2571, -0.3590,  ..., -0.1496, -0.3428, -0.3473]),\n",
       " tensor([17.3284, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 3.0705, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3129]),\n",
       " tensor([-0.0307, -0.3465, -0.2550,  ..., -0.2807, -0.1980, -0.3345]),\n",
       " tensor([-0.2640, -0.0451, -0.2809,  ..., -0.3184,  0.2579, -0.0862]),\n",
       " tensor([ 3.4968, -0.0000, -0.0048,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([177.4738,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000, 235.4417]),\n",
       " tensor([2.4365, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 1.1101,  0.2685, -0.0439,  ..., -0.2789, -0.0000,  0.6667]),\n",
       " tensor([-0.0517, -0.0620, -0.0433,  ...,  0.0009,  0.4910, -0.1110]),\n",
       " tensor([-0.3346, -0.0000,  4.1272,  ...,  2.3540, -0.0000, -0.0000]),\n",
       " tensor([-0.0000, -0.3508, -0.0000,  ..., -0.2222, -0.0000, -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([2.1370, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([ 0.3397, -0.0837, -0.3749,  ..., -0.2436, -0.1436, -0.3365]),\n",
       " tensor([-0.1703, -0.1666, -0.1836,  ..., -0.1245,  0.8360, -0.2874]),\n",
       " tensor([-0.2634,  0.1038, -0.0913,  ..., -0.2880, -0.2085, -0.3315]),\n",
       " tensor([ 0.0616, -0.1745,  0.1921,  ..., -0.2367, -0.3379, -0.3520]),\n",
       " tensor([ 1.1699, -0.0000, -0.1223,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.3124, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([1.4033, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]),\n",
       " tensor([-0.2791,  0.2496, -0.1272,  ..., -0.2375, -0.0484, -0.1328]),\n",
       " tensor([130.7687,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3247,  1.0298,  0.7555,  ...,  0.1074, -0.2593,  0.7236]),\n",
       " tensor([246.2902,  -0.0000,  -0.0000,  ...,  -0.0000,  -0.0000,  -0.0000]),\n",
       " tensor([-0.3104, -0.3613, -0.2019,  ..., -0.1185, -0.3412, -0.3592]),\n",
       " tensor([ 0.0749, -0.0832, -0.1264,  ..., -0.0521, -0.3208, -0.3682]),\n",
       " tensor([-0.0264,  0.2813, -0.3207,  ..., -0.3452, -0.3243, -0.3050]),\n",
       " tensor([-0.3202, -0.3745, -0.3652,  ..., -0.2643, -0.3060, -0.1636]),\n",
       " tensor([ 1.6143, -0.3535, -0.3161,  ..., -0.1343, -0.0000, -0.3071]),\n",
       " tensor([-0.3745, -0.3431, -0.1891,  ..., -0.2636, -0.2578, -0.3008]),\n",
       " tensor([753.3815,  39.1733,  -0.0000,  ...,  -0.0000,  -0.0000, 941.9702]),\n",
       " tensor([-0.0933, -0.3483, -0.2369,  ..., -0.3367, -0.0000, -0.1483]),\n",
       " tensor([4.3958, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 1.7537]),\n",
       " tensor([-0., -0., -0.,  ..., -0., -0., -0.]),\n",
       " tensor([-0.3385,  0.2425,  0.0673,  ..., -0.3709, -0.3543,  0.1985]),\n",
       " tensor([-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 3.3428]),\n",
       " tensor([ 0.6304, -0.0000, -0.0000,  ..., -0.1832, -0.2282, -0.0000]),\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['f_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9   ...  35  36  37  38  39  40  \\\n",
       "0       5   5   3   7   3   3   5   5   7   5  ...   4   4   6   6   6   4   \n",
       "1       5   3   5   3   7   7   5   5   7   5  ...   3   6   6   6   6   2   \n",
       "2       3   3   7   7   5   5   7   3   5   3  ...   6   6   3   6   6   4   \n",
       "3       7   7   7   7   3   5   7   3   3   7  ...   3   6   6   4   4   3   \n",
       "4       7   5   3   7   5   5   3   7   3   5  ...   6   4   4   6   4   3   \n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "13995   3   5   5   5   3   5   3   7   5   7  ...   4   6   6   6   6   2   \n",
       "13996   3   5   3   5   5   7   5   3   7   7  ...   6   3   3   3   6   2   \n",
       "13997   7   3   5   5   7   5   5   5   7   5  ...   6   6   4   6   4   3   \n",
       "13998   7   7   7   5   3   5   7   7   5   3  ...   6   6   6   6   4   4   \n",
       "13999   5   3   5   5   3   7   5   3   5   3  ...   3   3   3   3   3   2   \n",
       "\n",
       "       41  42  43  44  \n",
       "0       3   2   3   2  \n",
       "1       2   3   4   2  \n",
       "2       2   2   3   2  \n",
       "3       2   4   4   2  \n",
       "4       3   2   2   4  \n",
       "...    ..  ..  ..  ..  \n",
       "13995   3   2   2   2  \n",
       "13996   2   3   4   3  \n",
       "13997   4   2   4   4  \n",
       "13998   2   2   4   3  \n",
       "13999   4   4   2   2  \n",
       "\n",
       "[14000 rows x 45 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(files['topol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "009968b2b12cf2d95f017c4bd9caf3d88fcc91068568941b09b4c2bb4a140eff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pytorch_19': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
