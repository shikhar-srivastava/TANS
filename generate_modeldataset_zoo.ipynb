{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Zoo Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Read pt file from path \n",
    "#path = '/l/users/shikhar.srivastava/data/ofa/www.dropbox.com/s/1qbsgjqanxgw2ji/p_m_train.pt'\n",
    "path ='/nfs/projects/mbzuai/shikhar/datasets/ofa/p_m_train.pt' #p_mod_zoo.pt\n",
    "data_files = torch.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['6000-store-items-images-classified-by-color_imoore_0_12', 'ads5035-01_0_2', 'ai2020f_0_11', 'aia-dl-mid_0_4', 'apparel-images-dataset_trolukovich_0_12', 'apparel-images-dataset_trolukovich_12_24', 'asl-alphabet_grassknoted_0_15', 'asl-alphabet_grassknoted_15_29', 'best-artworks-of-all-time_ikarus777_0_17', 'best-artworks-of-all-time_ikarus777_17_34', 'best-artworks-of-all-time_ikarus777_34_51', 'blood-cells_paultimothymooney_0_4', 'breakhis_ambarish_0_8', 'breast-histopathology-images_paultimothymooney_0_2', 'cactus-aerial-photos_irvingvasquez_0_2', 'car-classificationproject-vision_0_15', 'car-classificationproject-vision_15_30', 'car-classificationproject-vision_30_45', 'cassava-leaf-disease-classification_0_5', 'celeba-dataset_jessicali9530_0_2', 'chessman-image-dataset_niteshfre_0_6', 'classification-of-handwritten-letters_olgabelitskaya_0_17', 'classification-of-handwritten-letters_olgabelitskaya_17_33', 'computed-tomography-ct-images_vbookshelf_0_2', 'corales_0_14', 'crack-identification-ce784a-2020-iitk_0_2', 'cs4487-2020fall_0_2', 'cs4670spring2020pa3_0_16', 'csep546-aut19-kc2_0_5', 'cv2020-classification-challenge_0_20', 'cv2020-classification-challenge_100_120', 'cv2020-classification-challenge_20_40', 'cv2020-classification-challenge_40_60', 'cv2020-classification-challenge_60_80', 'cv2020-classification-challenge_80_100', 'day-3-kaggle-competition_0_5', 'defi1-ia_0_3', 'devanagari-character-set_rishianand_0_16', 'devanagari-character-set_rishianand_16_31', 'devanagari-character-set_rishianand_31_46', 'DL2020_0_4', 'dlai3_0_2', 'e4040fall2019-assignment-2-task-5_0_5', 'fcis-sc-deeplearning-competition_0_10', 'flowers-recognition_alxmamaev_0_5', 'four-shapes_smeschke_0_4', 'fruit-recognition_chrisfilo_0_15', 'fruits_moltean_0_19', 'fruits_moltean_113_131', 'fruits_moltean_19_38', 'fruits_moltean_38_57', 'fruits_moltean_57_76', 'fruits_moltean_76_95', 'fruits_moltean_95_113', 'garbage-classification_asdasdasasdas_0_6', 'gen-2-ai-force-challenge-1_0_10', 'gpa759-2020_0_17', 'gpa759-2020_17_34', 'gpa759-2020_34_50', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_0_15', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_15_29', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_29_43', 'hackathon-blossom-flower-classification_spaics_0_17', 'hackathon-blossom-flower-classification_spaics_17_34', 'hackathon-blossom-flower-classification_spaics_34_51', 'hackathon-blossom-flower-classification_spaics_51_68', 'hackathon-blossom-flower-classification_spaics_68_85', 'hackathon-blossom-flower-classification_spaics_85_102', 'image-classification_duttadebadri_0_4', 'intel-image-classification_puneet6060_0_6', 'khu-deep-learning-competition_0_10', 'kunstmatigeintelligentie20192020_0_5', 'labeled-surgical-tools_dilavado_0_4', 'land-cover-class_0_10', 'lego-brick-images_joosthazelzet_0_16', 'lego-brick-sorting-image-recognition_pacogarciam3_0_20', 'lego-minifigures-classification_ihelon_0_14', 'lego-vs-generic-brick-image-recognition_pacogarciam3_0_4', 'make-up-vs-no-make-up_petersunga_0_2', 'malefemale-for-drr_0_2', 'messy-vs-clean-room_cdawn1_0_2', 'microsoft-catsvsdogs-dataset_shaunthesheep_0_2', 'mis583-hw2-part-2_0_5', 'mllabgame_0_10', 'mushrooms-classification-common-genuss-images_maysee_0_9', 'mvtec_anomaly_detection_carpet_0_6', 'mvtec_anomaly_detection_grid_0_6', 'mvtec_anomaly_detection_leather_0_6', 'nnfl-cnn-lab2_0_6', 'notmnist_jwjohnson314_0_10', 'numta_BengaliAI_0_10', 'nuu-me-midterm-exam-image-classification_0_5', 'oregon-wildlife_virtualdvid_0_20', 'parkinsons-drawings_kmader_0_2', 'perritos_0_10', 'plant-seedlings-classification_0_12', 'proptit-aif-homework-1_0_8', 'real-and-fake-face-detection_ciplab_0_2', 'real-life-industrial-dataset-of-casting-product_ravirajsinh45_0_2', 'rockpaperscissors_drgfreeman_0_3', 'sample_nih-chest-xrays_0_2', 'sfu-cmpt-computer-vision-course-cnn_0_20', 'sfu-cmpt-computer-vision-course-cnn_100_120', 'sfu-cmpt-computer-vision-course-cnn_120_140', 'sfu-cmpt-computer-vision-course-cnn_140_160', 'sfu-cmpt-computer-vision-course-cnn_160_180', 'sfu-cmpt-computer-vision-course-cnn_180_200', 'simpsons4_0_20', 'sfu-cmpt-computer-vision-course-cnn_20_40', 'sfu-cmpt-computer-vision-course-cnn_40_60', 'sfu-cmpt-computer-vision-course-cnn_60_80', 'sfu-cmpt-computer-vision-course-cnn_80_100', 'sheep-breed-classification_divyansh22_0_4', 'simpsons4_20_39', 'simpsons-challenge-gft_0_20', 'simpsons-challenge-gft_20_39', 'skin-cancer9-classesisic_nodoubttome_0_9', 'sldc_0_10', 'stanford-dogs-dataset_jessicali9530_0_20', 'stanford-dogs-dataset_jessicali9530_100_120', 'stanford-dogs-dataset_jessicali9530_20_40', 'stanford-dogs-dataset_jessicali9530_40_60', 'stanford-dogs-dataset_jessicali9530_60_80', 'stanford-dogs-dataset_jessicali9530_80_100', 'stanford-dogs-dataset-traintest_miljan_0_20', 'stanford-dogs-dataset-traintest_miljan_100_120', 'stanford-dogs-dataset-traintest_miljan_20_40', 'stanford-dogs-dataset-traintest_miljan_40_60', 'stanford-dogs-dataset-traintest_miljan_60_80', 'stanford-dogs-dataset-traintest_miljan_80_100', 'synthetic-digits_prasunroy_0_10', 'tau-ethiopic-digit-recognition_0_10', 'the-simpsons-characters-dataset_alexattia_0_20', 'the-simpsons-characters-dataset_alexattia_20_39', 'tl-signs-hse-itmo-2020-winter_0_17', 'tl-signs-hse-itmo-2020-winter_17_34', 'tl-signs-hse-itmo-2020-winter_34_51', 'tl-signs-hse-itmo-2020-winter_51_67', 'vehicle_0_17', 'zalando-store-crawl_dqmonn_0_6'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['6000-store-items-images-classified-by-color_imoore_0_12', 'ads5035-01_0_2', 'ai2020f_0_11', 'aia-dl-mid_0_4', 'apparel-images-dataset_trolukovich_0_12', 'apparel-images-dataset_trolukovich_12_24', 'asl-alphabet_grassknoted_0_15', 'asl-alphabet_grassknoted_15_29', 'best-artworks-of-all-time_ikarus777_0_17', 'best-artworks-of-all-time_ikarus777_17_34', 'best-artworks-of-all-time_ikarus777_34_51', 'blood-cells_paultimothymooney_0_4', 'breakhis_ambarish_0_8', 'breast-histopathology-images_paultimothymooney_0_2', 'cactus-aerial-photos_irvingvasquez_0_2', 'car-classificationproject-vision_0_15', 'car-classificationproject-vision_15_30', 'car-classificationproject-vision_30_45', 'cassava-leaf-disease-classification_0_5', 'celeba-dataset_jessicali9530_0_2', 'chessman-image-dataset_niteshfre_0_6', 'classification-of-handwritten-letters_olgabelitskaya_0_17', 'classification-of-handwritten-letters_olgabelitskaya_17_33', 'computed-tomography-ct-images_vbookshelf_0_2', 'corales_0_14', 'crack-identification-ce784a-2020-iitk_0_2', 'cs4487-2020fall_0_2', 'cs4670spring2020pa3_0_16', 'csep546-aut19-kc2_0_5', 'cv2020-classification-challenge_0_20', 'cv2020-classification-challenge_100_120', 'cv2020-classification-challenge_20_40', 'cv2020-classification-challenge_40_60', 'cv2020-classification-challenge_60_80', 'cv2020-classification-challenge_80_100', 'day-3-kaggle-competition_0_5', 'defi1-ia_0_3', 'devanagari-character-set_rishianand_0_16', 'devanagari-character-set_rishianand_16_31', 'devanagari-character-set_rishianand_31_46', 'DL2020_0_4', 'dlai3_0_2', 'e4040fall2019-assignment-2-task-5_0_5', 'fcis-sc-deeplearning-competition_0_10', 'flowers-recognition_alxmamaev_0_5', 'four-shapes_smeschke_0_4', 'fruit-recognition_chrisfilo_0_15', 'fruits_moltean_0_19', 'fruits_moltean_113_131', 'fruits_moltean_19_38', 'fruits_moltean_38_57', 'fruits_moltean_57_76', 'fruits_moltean_76_95', 'fruits_moltean_95_113', 'garbage-classification_asdasdasasdas_0_6', 'gen-2-ai-force-challenge-1_0_10', 'gpa759-2020_0_17', 'gpa759-2020_17_34', 'gpa759-2020_34_50', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_0_15', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_15_29', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_29_43', 'hackathon-blossom-flower-classification_spaics_0_17', 'hackathon-blossom-flower-classification_spaics_17_34', 'hackathon-blossom-flower-classification_spaics_34_51', 'hackathon-blossom-flower-classification_spaics_51_68', 'hackathon-blossom-flower-classification_spaics_68_85', 'hackathon-blossom-flower-classification_spaics_85_102', 'image-classification_duttadebadri_0_4', 'intel-image-classification_puneet6060_0_6', 'khu-deep-learning-competition_0_10', 'kunstmatigeintelligentie20192020_0_5', 'labeled-surgical-tools_dilavado_0_4', 'land-cover-class_0_10', 'lego-brick-images_joosthazelzet_0_16', 'lego-brick-sorting-image-recognition_pacogarciam3_0_20', 'lego-minifigures-classification_ihelon_0_14', 'lego-vs-generic-brick-image-recognition_pacogarciam3_0_4', 'make-up-vs-no-make-up_petersunga_0_2', 'malefemale-for-drr_0_2', 'messy-vs-clean-room_cdawn1_0_2', 'microsoft-catsvsdogs-dataset_shaunthesheep_0_2', 'mis583-hw2-part-2_0_5', 'mllabgame_0_10', 'mushrooms-classification-common-genuss-images_maysee_0_9', 'mvtec_anomaly_detection_carpet_0_6', 'mvtec_anomaly_detection_grid_0_6', 'mvtec_anomaly_detection_leather_0_6', 'nnfl-cnn-lab2_0_6', 'notmnist_jwjohnson314_0_10', 'numta_BengaliAI_0_10', 'nuu-me-midterm-exam-image-classification_0_5', 'oregon-wildlife_virtualdvid_0_20', 'parkinsons-drawings_kmader_0_2', 'perritos_0_10', 'plant-seedlings-classification_0_12', 'proptit-aif-homework-1_0_8', 'real-and-fake-face-detection_ciplab_0_2', 'real-life-industrial-dataset-of-casting-product_ravirajsinh45_0_2', 'rockpaperscissors_drgfreeman_0_3', 'sample_nih-chest-xrays_0_2', 'sfu-cmpt-computer-vision-course-cnn_0_20', 'sfu-cmpt-computer-vision-course-cnn_100_120', 'sfu-cmpt-computer-vision-course-cnn_120_140', 'sfu-cmpt-computer-vision-course-cnn_140_160', 'sfu-cmpt-computer-vision-course-cnn_160_180', 'sfu-cmpt-computer-vision-course-cnn_180_200', 'simpsons4_0_20', 'sfu-cmpt-computer-vision-course-cnn_20_40', 'sfu-cmpt-computer-vision-course-cnn_40_60', 'sfu-cmpt-computer-vision-course-cnn_60_80', 'sfu-cmpt-computer-vision-course-cnn_80_100', 'sheep-breed-classification_divyansh22_0_4', 'simpsons4_20_39', 'simpsons-challenge-gft_0_20', 'simpsons-challenge-gft_20_39', 'skin-cancer9-classesisic_nodoubttome_0_9', 'sldc_0_10', 'stanford-dogs-dataset_jessicali9530_0_20', 'stanford-dogs-dataset_jessicali9530_100_120', 'stanford-dogs-dataset_jessicali9530_20_40', 'stanford-dogs-dataset_jessicali9530_40_60', 'stanford-dogs-dataset_jessicali9530_60_80', 'stanford-dogs-dataset_jessicali9530_80_100', 'stanford-dogs-dataset-traintest_miljan_0_20', 'stanford-dogs-dataset-traintest_miljan_100_120', 'stanford-dogs-dataset-traintest_miljan_20_40', 'stanford-dogs-dataset-traintest_miljan_40_60', 'stanford-dogs-dataset-traintest_miljan_60_80', 'stanford-dogs-dataset-traintest_miljan_80_100', 'synthetic-digits_prasunroy_0_10', 'tau-ethiopic-digit-recognition_0_10', 'the-simpsons-characters-dataset_alexattia_0_20', 'the-simpsons-characters-dataset_alexattia_20_39', 'tl-signs-hse-itmo-2020-winter_0_17', 'tl-signs-hse-itmo-2020-winter_17_34', 'tl-signs-hse-itmo-2020-winter_34_51', 'tl-signs-hse-itmo-2020-winter_51_67', 'vehicle_0_17', 'zalando-store-crawl_dqmonn_0_6'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['task', 'clss', 'nclss', 'x_query_train', 'y_query_train', 'x_query_test', 'y_query_test'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files['6000-store-items-images-classified-by-color_imoore_0_12'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(data_files['stanford-dogs-dataset_jessicali9530_40_60']['x_query_train']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(data_files['6000-store-items-images-classified-by-color_imoore_0_12']['x_query_test']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataset Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta.embedding import DatasetEmbeddings\n",
    "import torch\n",
    "dataset_embed = DatasetEmbeddings(n_samples = 200)\n",
    "data_dict = dataset_embed.parse_and_embed()\n",
    "torch.save(data_dict,'/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_train.pt' )\n",
    "# Save the data_train dictionary as pt file\n",
    "#torch.save(data_dict, '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_m_train.pt')\n",
    "torch.save(data_dict,'/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_train.pt' )\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    print(key, len(value['x_query_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30533/3022977385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ImageCHD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "data_dict['ImageCHD'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCHD 20\n",
      "MosMed 20\n",
      "kits 20\n",
      "pc 20\n",
      "RSPECT 20\n",
      "chex 20\n",
      "IHD_Brain 20\n",
      "Brain_MRI 20\n",
      "CTPancreas 20\n",
      "nih 20\n",
      "ProstateMRI 20\n",
      "LiTs 20\n"
     ]
    }
   ],
   "source": [
    "for key, value in data_dict.items():\n",
    "    print(key, len(value['x_query_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Save the data_train dictionary as pt file\n",
    "#torch.save(data_dict, '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_m_train.pt')\n",
    "torch.save(data_dict,'/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_train.pt' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torchxrayvision as xrv\n",
    "nih_path = '/nfs/projects/mbzuai/shikhar/datasets/nih/images'\n",
    "chexpert_path = '/nfs/projects/mbzuai/shikhar/datasets/chexpert_small/CheXpert-v1.0-small'\n",
    "padchest_path = '/nfs/projects/mbzuai/shikhar/datasets/padchest'\n",
    "mimic_path = '/nfs/projects/mbzuai/shikhar/datasets/mimic/physionet.org/files/mimic-cxr-jpg/2.0.0'\n",
    "dataset = xrv.datasets.MIMIC_Dataset(\n",
    "                imgpath=mimic_path + '/files',\n",
    "                csvpath=mimic_path +'/mimic-cxr-2.0.0-metadata.csv.gz',\n",
    "                metacsvpath=mimic_path +'/mimic-cxr-2.0.0-chexpert.csv.gz',\n",
    "                transform=None, data_aug=None, unique_patients=False)\n",
    "dataset.pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.stack(data_dict['MosMed']['x_query_train']).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Read pt file from path \n",
    "#path = '/l/users/shikhar.srivastava/data/ofa/www.dropbox.com/s/1qbsgjqanxgw2ji/p_m_train.pt'\n",
    "path ='/nfs/projects/mbzuai/shikhar/datasets/ofa/p_mod_zoo.pt' #p_mod_zoo.pt\n",
    "model_files = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset', 'acc', 'n_params', 'topol', 'f_emb'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_epoch', 'f1', 'loss', 'model_path', 'dataset', 'model', 'with_aug', 'imagenet_pretrained', 'f_emb', 'acc', 'topn'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['f_emb'][10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Xrays!\n",
      "=====================\n",
      "Sanity Model Parse\n",
      "Unknowns:  0\n",
      "Empty DataFrame\n",
      "Columns: [best_epoch, acc, f1, loss, model_path, dataset, model, with_aug, balanced, pretrained, batch_128, topn]\n",
      "Index: []\n",
      "=====================\n",
      "[Errno 2] No such file or directory: '/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/top-7/Feb25_01-20-42_p4-r66-b.g42cloud.net_classify_top-7_resnet18_RSPECT_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt'\n",
      "[Model Loading Error]\n",
      "/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/top-7/Feb25_01-20-42_p4-r66-b.g42cloud.net_classify_top-7_resnet18_RSPECT_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt\n",
      "resnet18\n"
     ]
    }
   ],
   "source": [
    "from meta.embedding import ModelEmbeddings\n",
    "model_embed = ModelEmbeddings()\n",
    "_model_dict = model_embed.parse_and_embed()\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(_model_dict)\n",
    "model_dict = df.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_epoch', 'acc', 'f1', 'loss', 'model_path', 'dataset', 'model', 'with_aug', 'balanced', 'pretrained', 'batch_128', 'topn', 'f_emb'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>model_path</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>with_aug</th>\n",
       "      <th>balanced</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>batch_128</th>\n",
       "      <th>topn</th>\n",
       "      <th>f_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>IHD_Brain</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.439231</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>IHD_Brain</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.507455</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.235808</td>\n",
       "      <td>0.549068</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>42</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.780415</td>\n",
       "      <td>0.259087</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>CTPancreas</td>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.0308), tensor(-0.0279), tensor(-0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>22</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.089775</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ImageCHD</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(2.0657), tensor(2.1143), tensor(1.8511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>44</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>MosMed</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>88</td>\n",
       "      <td>0.531792</td>\n",
       "      <td>0.531792</td>\n",
       "      <td>1.122675</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>Covid19XRay</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>35</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.471072</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ProstateMRI</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_epoch       acc        f1      loss  \\\n",
       "0            46  0.826667  0.452632  0.278173   \n",
       "1            97  0.790000  0.790698  0.439231   \n",
       "2            11  0.776667  0.263736  0.507455   \n",
       "3            16  0.708333  0.235808  0.549068   \n",
       "4            95  0.950000  0.210526  0.150664   \n",
       "..          ...       ...       ...       ...   \n",
       "322          42  0.855469  0.780415  0.259087   \n",
       "323          22  0.818750  0.188811  0.089775   \n",
       "324          44  0.759375  0.702703  0.143112   \n",
       "325          88  0.531792  0.531792  1.122675   \n",
       "326          35  0.773438  0.594406  0.471072   \n",
       "\n",
       "                                            model_path      dataset  \\\n",
       "0    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    IHD_Brain   \n",
       "1    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    IHD_Brain   \n",
       "2    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "3    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "4    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "..                                                 ...          ...   \n",
       "322  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...   CTPancreas   \n",
       "323  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...     ImageCHD   \n",
       "324  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       MosMed   \n",
       "325  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...  Covid19XRay   \n",
       "326  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...  ProstateMRI   \n",
       "\n",
       "               model  with_aug  balanced  pretrained  batch_128   topn  \\\n",
       "0           resnet18     False     False       False      False  top-2   \n",
       "1           resnet50      True      True       False       True  top-2   \n",
       "2           resnet18      True     False        True       True  top-2   \n",
       "3       mobilenet_v2      True     False       False       True  top-2   \n",
       "4           resnet50      True     False       False      False  top-2   \n",
       "..               ...       ...       ...         ...        ...    ...   \n",
       "322  efficientnet_b4      True     False       False       True    raw   \n",
       "323     mobilenet_v2      True     False       False      False    raw   \n",
       "324         resnet18      True     False       False      False    raw   \n",
       "325         resnet18      True     False        True       True    raw   \n",
       "326         resnet50      True     False       False       True    raw   \n",
       "\n",
       "                                                 f_emb  \n",
       "0    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "1    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "2    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "3    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "4    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "..                                                 ...  \n",
       "322  [tensor(0.0308), tensor(-0.0279), tensor(-0.01...  \n",
       "323  [tensor(2.0657), tensor(2.1143), tensor(1.8511...  \n",
       "324  [tensor(0.), tensor(0.), tensor(0.), tensor(2....  \n",
       "325  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "326  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "\n",
       "[327 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model_dict, '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_mod_zoo.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_epoch', 'f1', 'loss', 'model_path', 'dataset', 'model', 'with_aug', 'imagenet_pretrained', 'f_emb', 'acc', 'topn'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['f_emb'][10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "for row in df['f_emb']:\n",
    "    clear_output(wait = False)\n",
    "    print(row.numpy().shape)\n",
    "    print(list(row.numpy()))\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>model_path</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>with_aug</th>\n",
       "      <th>balanced</th>\n",
       "      <th>topn</th>\n",
       "      <th>f_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>IHD_Brain</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.507455</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.235808</td>\n",
       "      <td>0.549068</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.451216</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9</td>\n",
       "      <td>0.819531</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.442918</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ImageCHD</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(41.2831), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>42</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.780415</td>\n",
       "      <td>0.259087</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>CTPancreas</td>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.0308), tensor(-0.0279), tensor(-0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>22</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.089775</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ImageCHD</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(2.0657), tensor(2.1143), tensor(1.8511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>44</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>MosMed</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>35</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.471072</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ProstateMRI</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_epoch       acc        f1      loss  \\\n",
       "0            46  0.826667  0.452632  0.278173   \n",
       "1            11  0.776667  0.263736  0.507455   \n",
       "2            16  0.708333  0.235808  0.549068   \n",
       "3            95  0.950000  0.210526  0.150664   \n",
       "4            18  0.813333  0.827692  0.451216   \n",
       "..          ...       ...       ...       ...   \n",
       "295           9  0.819531  0.094118  0.442918   \n",
       "296          42  0.855469  0.780415  0.259087   \n",
       "297          22  0.818750  0.188811  0.089775   \n",
       "298          44  0.759375  0.702703  0.143112   \n",
       "299          35  0.773438  0.594406  0.471072   \n",
       "\n",
       "                                            model_path      dataset  \\\n",
       "0    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    IHD_Brain   \n",
       "1    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "2    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "3    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "4    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "..                                                 ...          ...   \n",
       "295  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...     ImageCHD   \n",
       "296  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...   CTPancreas   \n",
       "297  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...     ImageCHD   \n",
       "298  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       MosMed   \n",
       "299  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...  ProstateMRI   \n",
       "\n",
       "               model  with_aug  balanced   topn  \\\n",
       "0           resnet18     False     False  top-2   \n",
       "1           resnet18      True     False  top-2   \n",
       "2       mobilenet_v2      True     False  top-2   \n",
       "3           resnet50      True     False  top-2   \n",
       "4       mobilenet_v2      True      True  top-2   \n",
       "..               ...       ...       ...    ...   \n",
       "295         resnet50      True     False    raw   \n",
       "296  efficientnet_b4      True     False    raw   \n",
       "297     mobilenet_v2      True     False    raw   \n",
       "298         resnet18      True     False    raw   \n",
       "299         resnet50      True     False    raw   \n",
       "\n",
       "                                                 f_emb  \n",
       "0    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "1    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "2    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "3    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "4    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "..                                                 ...  \n",
       "295  [tensor(0.), tensor(0.), tensor(41.2831), tens...  \n",
       "296  [tensor(0.0308), tensor(-0.0279), tensor(-0.01...  \n",
       "297  [tensor(2.0657), tensor(2.1143), tensor(1.8511...  \n",
       "298  [tensor(0.), tensor(0.), tensor(0.), tensor(2....  \n",
       "299  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import clear_output\n",
    "for row in df['x_query_train'][0]:\n",
    "    print(row.numpy().shape)\n",
    "    print(list(row.numpy()))\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38470bdf3e966986ca85f0825073bcf86ddf5dbb9002a7f4b160e6f6a6aff5a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ofa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
