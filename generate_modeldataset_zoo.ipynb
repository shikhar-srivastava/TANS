{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Zoo Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== Testing dataset:  recognizance1_0_5\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "1324 334 1324 334\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([50, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  gemstones-images_lsind18_18_36\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "432 119 432 119\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([180, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  drr-sign_0_4\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "272 71 272 71\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([40, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  ucfai-core-fa19-cnns_76_95\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "754 197 754 197\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([190, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  honey-bee-pollen_ivanfel_0_2\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "571 143 571 143\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([20, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  alien-vs-predator-images_pmigdal_0_2\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "711 179 711 179\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([20, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  kuzushiji_anokas_1120_1140\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "940 245 940 245\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([192, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  covid19-radiography-database_tawsifurrahman_0_3\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "2298 576 2298 576\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([30, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  colorectal-histology-mnist_kmader_0_8\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "4000 1000 4000 1000\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([80, 512])\n",
      "====================================================\n",
      "========================== Testing dataset:  ml2020spring-hw12_0_10\n",
      "dict_keys(['task', 'clss', 'nclss', 'x_train', 'y_train', 'x_test', 'y_test', 'query'])\n",
      "4000 1000 4000 1000\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([100, 512])\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "path = '/nfs/projects/mbzuai/shikhar/datasets/ofa/data_path/meta_test_'\n",
    "test_datasets = [\n",
    "                'recognizance1_0_5',\n",
    "                'gemstones-images_lsind18_18_36',\n",
    "                'drr-sign_0_4',\n",
    "                'ucfai-core-fa19-cnns_76_95',\n",
    "                'honey-bee-pollen_ivanfel_0_2',\n",
    "                'alien-vs-predator-images_pmigdal_0_2',\n",
    "                'kuzushiji_anokas_1120_1140',\n",
    "                'covid19-radiography-database_tawsifurrahman_0_3',\n",
    "                'colorectal-histology-mnist_kmader_0_8',\n",
    "                'ml2020spring-hw12_0_10',\n",
    "        ]\n",
    "import torch\n",
    "for dataset in test_datasets:\n",
    "    print('========================== Testing dataset: ', dataset)\n",
    "    data_ = torch.load(path + dataset + '.pt')\n",
    "    print(data_.keys())\n",
    "    print(len(data_['x_train']), len(data_['x_test']), len(data_['y_train']), len(data_['y_test']))\n",
    "    print(data_['x_train'][0].shape)\n",
    "    print(data_['query'].shape)\n",
    "    print('====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_['x_train'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def gen_leave4out():\n",
    "    MRI = [\"Brain_MRI\",\"ProstateMRI\"]\n",
    "    XRAY = [\"RSNAXRay\",\"Covid19XRay\"]\n",
    "    CT = [ \"MosMed\",\n",
    "    \"kits\",\n",
    "    \"LiTs\",\n",
    "    \"RSPECT\",\n",
    "    \"IHD_Brain\",\n",
    "    \"ImageCHD\",\n",
    "    \"CTPancreas\"]\n",
    "    # get all combinations of 2 CT datasets with 1 MRI and 1 XRAY\n",
    "    combs = []\n",
    "    for mri in MRI:\n",
    "        for xray in XRAY:\n",
    "            for (ct1,ct2) in combinations(CT, 2):\n",
    "                combs.append([ct1,ct2,mri,xray])\n",
    "    return combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['MosMed', 'kits', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['MosMed', 'LiTs', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['MosMed', 'RSPECT', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['MosMed', 'IHD_Brain', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['MosMed', 'ImageCHD', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['MosMed', 'CTPancreas', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['kits', 'LiTs', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['kits', 'RSPECT', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['kits', 'IHD_Brain', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['kits', 'ImageCHD', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['kits', 'CTPancreas', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['LiTs', 'RSPECT', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['LiTs', 'IHD_Brain', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['LiTs', 'ImageCHD', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['LiTs', 'CTPancreas', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['RSPECT', 'IHD_Brain', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['RSPECT', 'ImageCHD', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['RSPECT', 'CTPancreas', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['IHD_Brain', 'ImageCHD', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['IHD_Brain', 'CTPancreas', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['ImageCHD', 'CTPancreas', 'Brain_MRI', 'RSNAXRay'],\n",
       " ['MosMed', 'kits', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['MosMed', 'LiTs', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['MosMed', 'RSPECT', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['MosMed', 'IHD_Brain', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['MosMed', 'ImageCHD', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['MosMed', 'CTPancreas', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['kits', 'LiTs', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['kits', 'RSPECT', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['kits', 'IHD_Brain', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['kits', 'ImageCHD', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['kits', 'CTPancreas', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['LiTs', 'RSPECT', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['LiTs', 'IHD_Brain', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['LiTs', 'ImageCHD', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['LiTs', 'CTPancreas', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['RSPECT', 'IHD_Brain', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['RSPECT', 'ImageCHD', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['RSPECT', 'CTPancreas', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['IHD_Brain', 'ImageCHD', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['IHD_Brain', 'CTPancreas', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['ImageCHD', 'CTPancreas', 'Brain_MRI', 'Covid19XRay'],\n",
       " ['MosMed', 'kits', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['MosMed', 'LiTs', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['MosMed', 'RSPECT', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['MosMed', 'IHD_Brain', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['MosMed', 'ImageCHD', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['MosMed', 'CTPancreas', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['kits', 'LiTs', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['kits', 'RSPECT', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['kits', 'IHD_Brain', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['kits', 'ImageCHD', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['kits', 'CTPancreas', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['LiTs', 'RSPECT', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['LiTs', 'IHD_Brain', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['LiTs', 'ImageCHD', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['LiTs', 'CTPancreas', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['RSPECT', 'IHD_Brain', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['RSPECT', 'ImageCHD', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['RSPECT', 'CTPancreas', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['IHD_Brain', 'ImageCHD', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['IHD_Brain', 'CTPancreas', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['ImageCHD', 'CTPancreas', 'ProstateMRI', 'RSNAXRay'],\n",
       " ['MosMed', 'kits', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['MosMed', 'LiTs', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['MosMed', 'RSPECT', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['MosMed', 'IHD_Brain', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['MosMed', 'ImageCHD', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['MosMed', 'CTPancreas', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['kits', 'LiTs', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['kits', 'RSPECT', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['kits', 'IHD_Brain', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['kits', 'ImageCHD', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['kits', 'CTPancreas', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['LiTs', 'RSPECT', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['LiTs', 'IHD_Brain', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['LiTs', 'ImageCHD', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['LiTs', 'CTPancreas', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['RSPECT', 'IHD_Brain', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['RSPECT', 'ImageCHD', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['RSPECT', 'CTPancreas', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['IHD_Brain', 'ImageCHD', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['IHD_Brain', 'CTPancreas', 'ProstateMRI', 'Covid19XRay'],\n",
       " ['ImageCHD', 'CTPancreas', 'ProstateMRI', 'Covid19XRay']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_leave4out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [05:28<00:00, 29.91s/it]\n"
     ]
    }
   ],
   "source": [
    "from meta.embedding import DatasetEmbeddings\n",
    "import torch\n",
    "data_embedding = DatasetEmbeddings()\n",
    "data_dict = data_embedding.meta_test_embed_datasets(n_samples = 200)\n",
    "# save torch \n",
    "data_embedding_path = '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_test_all.pt'\n",
    "# save data_dict to path\n",
    "torch.save(data_dict,data_embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Read pt file from path \n",
    "#path = '/l/users/shikhar.srivastava/data/ofa/www.dropbox.com/s/1qbsgjqanxgw2ji/p_m_train.pt'\n",
    "path ='/nfs/projects/mbzuai/shikhar/datasets/ofa/p_m_train.pt' #p_mod_zoo.pt\n",
    "data_files = torch.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['6000-store-items-images-classified-by-color_imoore_0_12', 'ads5035-01_0_2', 'ai2020f_0_11', 'aia-dl-mid_0_4', 'apparel-images-dataset_trolukovich_0_12', 'apparel-images-dataset_trolukovich_12_24', 'asl-alphabet_grassknoted_0_15', 'asl-alphabet_grassknoted_15_29', 'best-artworks-of-all-time_ikarus777_0_17', 'best-artworks-of-all-time_ikarus777_17_34', 'best-artworks-of-all-time_ikarus777_34_51', 'blood-cells_paultimothymooney_0_4', 'breakhis_ambarish_0_8', 'breast-histopathology-images_paultimothymooney_0_2', 'cactus-aerial-photos_irvingvasquez_0_2', 'car-classificationproject-vision_0_15', 'car-classificationproject-vision_15_30', 'car-classificationproject-vision_30_45', 'cassava-leaf-disease-classification_0_5', 'celeba-dataset_jessicali9530_0_2', 'chessman-image-dataset_niteshfre_0_6', 'classification-of-handwritten-letters_olgabelitskaya_0_17', 'classification-of-handwritten-letters_olgabelitskaya_17_33', 'computed-tomography-ct-images_vbookshelf_0_2', 'corales_0_14', 'crack-identification-ce784a-2020-iitk_0_2', 'cs4487-2020fall_0_2', 'cs4670spring2020pa3_0_16', 'csep546-aut19-kc2_0_5', 'cv2020-classification-challenge_0_20', 'cv2020-classification-challenge_100_120', 'cv2020-classification-challenge_20_40', 'cv2020-classification-challenge_40_60', 'cv2020-classification-challenge_60_80', 'cv2020-classification-challenge_80_100', 'day-3-kaggle-competition_0_5', 'defi1-ia_0_3', 'devanagari-character-set_rishianand_0_16', 'devanagari-character-set_rishianand_16_31', 'devanagari-character-set_rishianand_31_46', 'DL2020_0_4', 'dlai3_0_2', 'e4040fall2019-assignment-2-task-5_0_5', 'fcis-sc-deeplearning-competition_0_10', 'flowers-recognition_alxmamaev_0_5', 'four-shapes_smeschke_0_4', 'fruit-recognition_chrisfilo_0_15', 'fruits_moltean_0_19', 'fruits_moltean_113_131', 'fruits_moltean_19_38', 'fruits_moltean_38_57', 'fruits_moltean_57_76', 'fruits_moltean_76_95', 'fruits_moltean_95_113', 'garbage-classification_asdasdasasdas_0_6', 'gen-2-ai-force-challenge-1_0_10', 'gpa759-2020_0_17', 'gpa759-2020_17_34', 'gpa759-2020_34_50', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_0_15', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_15_29', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_29_43', 'hackathon-blossom-flower-classification_spaics_0_17', 'hackathon-blossom-flower-classification_spaics_17_34', 'hackathon-blossom-flower-classification_spaics_34_51', 'hackathon-blossom-flower-classification_spaics_51_68', 'hackathon-blossom-flower-classification_spaics_68_85', 'hackathon-blossom-flower-classification_spaics_85_102', 'image-classification_duttadebadri_0_4', 'intel-image-classification_puneet6060_0_6', 'khu-deep-learning-competition_0_10', 'kunstmatigeintelligentie20192020_0_5', 'labeled-surgical-tools_dilavado_0_4', 'land-cover-class_0_10', 'lego-brick-images_joosthazelzet_0_16', 'lego-brick-sorting-image-recognition_pacogarciam3_0_20', 'lego-minifigures-classification_ihelon_0_14', 'lego-vs-generic-brick-image-recognition_pacogarciam3_0_4', 'make-up-vs-no-make-up_petersunga_0_2', 'malefemale-for-drr_0_2', 'messy-vs-clean-room_cdawn1_0_2', 'microsoft-catsvsdogs-dataset_shaunthesheep_0_2', 'mis583-hw2-part-2_0_5', 'mllabgame_0_10', 'mushrooms-classification-common-genuss-images_maysee_0_9', 'mvtec_anomaly_detection_carpet_0_6', 'mvtec_anomaly_detection_grid_0_6', 'mvtec_anomaly_detection_leather_0_6', 'nnfl-cnn-lab2_0_6', 'notmnist_jwjohnson314_0_10', 'numta_BengaliAI_0_10', 'nuu-me-midterm-exam-image-classification_0_5', 'oregon-wildlife_virtualdvid_0_20', 'parkinsons-drawings_kmader_0_2', 'perritos_0_10', 'plant-seedlings-classification_0_12', 'proptit-aif-homework-1_0_8', 'real-and-fake-face-detection_ciplab_0_2', 'real-life-industrial-dataset-of-casting-product_ravirajsinh45_0_2', 'rockpaperscissors_drgfreeman_0_3', 'sample_nih-chest-xrays_0_2', 'sfu-cmpt-computer-vision-course-cnn_0_20', 'sfu-cmpt-computer-vision-course-cnn_100_120', 'sfu-cmpt-computer-vision-course-cnn_120_140', 'sfu-cmpt-computer-vision-course-cnn_140_160', 'sfu-cmpt-computer-vision-course-cnn_160_180', 'sfu-cmpt-computer-vision-course-cnn_180_200', 'simpsons4_0_20', 'sfu-cmpt-computer-vision-course-cnn_20_40', 'sfu-cmpt-computer-vision-course-cnn_40_60', 'sfu-cmpt-computer-vision-course-cnn_60_80', 'sfu-cmpt-computer-vision-course-cnn_80_100', 'sheep-breed-classification_divyansh22_0_4', 'simpsons4_20_39', 'simpsons-challenge-gft_0_20', 'simpsons-challenge-gft_20_39', 'skin-cancer9-classesisic_nodoubttome_0_9', 'sldc_0_10', 'stanford-dogs-dataset_jessicali9530_0_20', 'stanford-dogs-dataset_jessicali9530_100_120', 'stanford-dogs-dataset_jessicali9530_20_40', 'stanford-dogs-dataset_jessicali9530_40_60', 'stanford-dogs-dataset_jessicali9530_60_80', 'stanford-dogs-dataset_jessicali9530_80_100', 'stanford-dogs-dataset-traintest_miljan_0_20', 'stanford-dogs-dataset-traintest_miljan_100_120', 'stanford-dogs-dataset-traintest_miljan_20_40', 'stanford-dogs-dataset-traintest_miljan_40_60', 'stanford-dogs-dataset-traintest_miljan_60_80', 'stanford-dogs-dataset-traintest_miljan_80_100', 'synthetic-digits_prasunroy_0_10', 'tau-ethiopic-digit-recognition_0_10', 'the-simpsons-characters-dataset_alexattia_0_20', 'the-simpsons-characters-dataset_alexattia_20_39', 'tl-signs-hse-itmo-2020-winter_0_17', 'tl-signs-hse-itmo-2020-winter_17_34', 'tl-signs-hse-itmo-2020-winter_34_51', 'tl-signs-hse-itmo-2020-winter_51_67', 'vehicle_0_17', 'zalando-store-crawl_dqmonn_0_6'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['6000-store-items-images-classified-by-color_imoore_0_12', 'ads5035-01_0_2', 'ai2020f_0_11', 'aia-dl-mid_0_4', 'apparel-images-dataset_trolukovich_0_12', 'apparel-images-dataset_trolukovich_12_24', 'asl-alphabet_grassknoted_0_15', 'asl-alphabet_grassknoted_15_29', 'best-artworks-of-all-time_ikarus777_0_17', 'best-artworks-of-all-time_ikarus777_17_34', 'best-artworks-of-all-time_ikarus777_34_51', 'blood-cells_paultimothymooney_0_4', 'breakhis_ambarish_0_8', 'breast-histopathology-images_paultimothymooney_0_2', 'cactus-aerial-photos_irvingvasquez_0_2', 'car-classificationproject-vision_0_15', 'car-classificationproject-vision_15_30', 'car-classificationproject-vision_30_45', 'cassava-leaf-disease-classification_0_5', 'celeba-dataset_jessicali9530_0_2', 'chessman-image-dataset_niteshfre_0_6', 'classification-of-handwritten-letters_olgabelitskaya_0_17', 'classification-of-handwritten-letters_olgabelitskaya_17_33', 'computed-tomography-ct-images_vbookshelf_0_2', 'corales_0_14', 'crack-identification-ce784a-2020-iitk_0_2', 'cs4487-2020fall_0_2', 'cs4670spring2020pa3_0_16', 'csep546-aut19-kc2_0_5', 'cv2020-classification-challenge_0_20', 'cv2020-classification-challenge_100_120', 'cv2020-classification-challenge_20_40', 'cv2020-classification-challenge_40_60', 'cv2020-classification-challenge_60_80', 'cv2020-classification-challenge_80_100', 'day-3-kaggle-competition_0_5', 'defi1-ia_0_3', 'devanagari-character-set_rishianand_0_16', 'devanagari-character-set_rishianand_16_31', 'devanagari-character-set_rishianand_31_46', 'DL2020_0_4', 'dlai3_0_2', 'e4040fall2019-assignment-2-task-5_0_5', 'fcis-sc-deeplearning-competition_0_10', 'flowers-recognition_alxmamaev_0_5', 'four-shapes_smeschke_0_4', 'fruit-recognition_chrisfilo_0_15', 'fruits_moltean_0_19', 'fruits_moltean_113_131', 'fruits_moltean_19_38', 'fruits_moltean_38_57', 'fruits_moltean_57_76', 'fruits_moltean_76_95', 'fruits_moltean_95_113', 'garbage-classification_asdasdasasdas_0_6', 'gen-2-ai-force-challenge-1_0_10', 'gpa759-2020_0_17', 'gpa759-2020_17_34', 'gpa759-2020_34_50', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_0_15', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_15_29', 'gtsrb-german-traffic-sign_meowmeowmeowmeowmeow_29_43', 'hackathon-blossom-flower-classification_spaics_0_17', 'hackathon-blossom-flower-classification_spaics_17_34', 'hackathon-blossom-flower-classification_spaics_34_51', 'hackathon-blossom-flower-classification_spaics_51_68', 'hackathon-blossom-flower-classification_spaics_68_85', 'hackathon-blossom-flower-classification_spaics_85_102', 'image-classification_duttadebadri_0_4', 'intel-image-classification_puneet6060_0_6', 'khu-deep-learning-competition_0_10', 'kunstmatigeintelligentie20192020_0_5', 'labeled-surgical-tools_dilavado_0_4', 'land-cover-class_0_10', 'lego-brick-images_joosthazelzet_0_16', 'lego-brick-sorting-image-recognition_pacogarciam3_0_20', 'lego-minifigures-classification_ihelon_0_14', 'lego-vs-generic-brick-image-recognition_pacogarciam3_0_4', 'make-up-vs-no-make-up_petersunga_0_2', 'malefemale-for-drr_0_2', 'messy-vs-clean-room_cdawn1_0_2', 'microsoft-catsvsdogs-dataset_shaunthesheep_0_2', 'mis583-hw2-part-2_0_5', 'mllabgame_0_10', 'mushrooms-classification-common-genuss-images_maysee_0_9', 'mvtec_anomaly_detection_carpet_0_6', 'mvtec_anomaly_detection_grid_0_6', 'mvtec_anomaly_detection_leather_0_6', 'nnfl-cnn-lab2_0_6', 'notmnist_jwjohnson314_0_10', 'numta_BengaliAI_0_10', 'nuu-me-midterm-exam-image-classification_0_5', 'oregon-wildlife_virtualdvid_0_20', 'parkinsons-drawings_kmader_0_2', 'perritos_0_10', 'plant-seedlings-classification_0_12', 'proptit-aif-homework-1_0_8', 'real-and-fake-face-detection_ciplab_0_2', 'real-life-industrial-dataset-of-casting-product_ravirajsinh45_0_2', 'rockpaperscissors_drgfreeman_0_3', 'sample_nih-chest-xrays_0_2', 'sfu-cmpt-computer-vision-course-cnn_0_20', 'sfu-cmpt-computer-vision-course-cnn_100_120', 'sfu-cmpt-computer-vision-course-cnn_120_140', 'sfu-cmpt-computer-vision-course-cnn_140_160', 'sfu-cmpt-computer-vision-course-cnn_160_180', 'sfu-cmpt-computer-vision-course-cnn_180_200', 'simpsons4_0_20', 'sfu-cmpt-computer-vision-course-cnn_20_40', 'sfu-cmpt-computer-vision-course-cnn_40_60', 'sfu-cmpt-computer-vision-course-cnn_60_80', 'sfu-cmpt-computer-vision-course-cnn_80_100', 'sheep-breed-classification_divyansh22_0_4', 'simpsons4_20_39', 'simpsons-challenge-gft_0_20', 'simpsons-challenge-gft_20_39', 'skin-cancer9-classesisic_nodoubttome_0_9', 'sldc_0_10', 'stanford-dogs-dataset_jessicali9530_0_20', 'stanford-dogs-dataset_jessicali9530_100_120', 'stanford-dogs-dataset_jessicali9530_20_40', 'stanford-dogs-dataset_jessicali9530_40_60', 'stanford-dogs-dataset_jessicali9530_60_80', 'stanford-dogs-dataset_jessicali9530_80_100', 'stanford-dogs-dataset-traintest_miljan_0_20', 'stanford-dogs-dataset-traintest_miljan_100_120', 'stanford-dogs-dataset-traintest_miljan_20_40', 'stanford-dogs-dataset-traintest_miljan_40_60', 'stanford-dogs-dataset-traintest_miljan_60_80', 'stanford-dogs-dataset-traintest_miljan_80_100', 'synthetic-digits_prasunroy_0_10', 'tau-ethiopic-digit-recognition_0_10', 'the-simpsons-characters-dataset_alexattia_0_20', 'the-simpsons-characters-dataset_alexattia_20_39', 'tl-signs-hse-itmo-2020-winter_0_17', 'tl-signs-hse-itmo-2020-winter_17_34', 'tl-signs-hse-itmo-2020-winter_34_51', 'tl-signs-hse-itmo-2020-winter_51_67', 'vehicle_0_17', 'zalando-store-crawl_dqmonn_0_6'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['task', 'clss', 'nclss', 'x_query_train', 'y_query_train', 'x_query_test', 'y_query_test'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files['6000-store-items-images-classified-by-color_imoore_0_12'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(data_files['stanford-dogs-dataset_jessicali9530_40_60']['x_query_train']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(data_files['6000-store-items-images-classified-by-color_imoore_0_12']['x_query_test']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataset Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta.embedding import DatasetEmbeddings\n",
    "import torch\n",
    "dataset_embed = DatasetEmbeddings(n_samples = 200)\n",
    "data_dict = dataset_embed.parse_and_embed()\n",
    "torch.save(data_dict,'/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_train.pt' )\n",
    "# Save the data_train dictionary as pt file\n",
    "#torch.save(data_dict, '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_m_train.pt')\n",
    "torch.save(data_dict,'/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_train.pt' )\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    print(key, len(value['x_query_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30533/3022977385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ImageCHD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "data_dict['ImageCHD'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCHD 20\n",
      "MosMed 20\n",
      "kits 20\n",
      "pc 20\n",
      "RSPECT 20\n",
      "chex 20\n",
      "IHD_Brain 20\n",
      "Brain_MRI 20\n",
      "CTPancreas 20\n",
      "nih 20\n",
      "ProstateMRI 20\n",
      "LiTs 20\n"
     ]
    }
   ],
   "source": [
    "for key, value in data_dict.items():\n",
    "    print(key, len(value['x_query_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Save the data_train dictionary as pt file\n",
    "#torch.save(data_dict, '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_m_train.pt')\n",
    "torch.save(data_dict,'/nfs/projects/mbzuai/shikhar/datasets/ofa/our_data_path/meta_train.pt' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torchxrayvision as xrv\n",
    "nih_path = '/nfs/projects/mbzuai/shikhar/datasets/nih/images'\n",
    "chexpert_path = '/nfs/projects/mbzuai/shikhar/datasets/chexpert_small/CheXpert-v1.0-small'\n",
    "padchest_path = '/nfs/projects/mbzuai/shikhar/datasets/padchest'\n",
    "mimic_path = '/nfs/projects/mbzuai/shikhar/datasets/mimic/physionet.org/files/mimic-cxr-jpg/2.0.0'\n",
    "dataset = xrv.datasets.MIMIC_Dataset(\n",
    "                imgpath=mimic_path + '/files',\n",
    "                csvpath=mimic_path +'/mimic-cxr-2.0.0-metadata.csv.gz',\n",
    "                metacsvpath=mimic_path +'/mimic-cxr-2.0.0-chexpert.csv.gz',\n",
    "                transform=None, data_aug=None, unique_patients=False)\n",
    "dataset.pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.load('/nfs/users/ext_shikhar.srivastava/workspace/TANS/outcomes/ours/20220226_1107/retrieval/retrieval.pt', map_location = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 380\n",
      "m_emb 380\n",
      "acc 380\n",
      "f1 380\n",
      "best_epoch 0\n",
      "loss 380\n",
      "model_path 380\n",
      "model 380\n",
      "with_aug 380\n",
      "balanced 380\n",
      "pretrained 380\n",
      "batch_128 380\n",
      "topn 380\n"
     ]
    }
   ],
   "source": [
    "for key, value in x.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.stack(data_dict['MosMed']['x_query_train']).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Read pt file from path \n",
    "#path = '/l/users/shikhar.srivastava/data/ofa/www.dropbox.com/s/1qbsgjqanxgw2ji/p_m_train.pt'\n",
    "path ='/nfs/projects/mbzuai/shikhar/datasets/ofa/p_mod_zoo.pt' #p_mod_zoo.pt\n",
    "model_files = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset', 'acc', 'n_params', 'topol', 'f_emb'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_epoch', 'f1', 'loss', 'model_path', 'dataset', 'model', 'with_aug', 'imagenet_pretrained', 'f_emb', 'acc', 'topn'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['f_emb'][10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Xrays!\n",
      "=====================\n",
      "Sanity Model Parse\n",
      "Unknowns:  0\n",
      "Empty DataFrame\n",
      "Columns: [best_epoch, acc, f1, loss, model_path, dataset, model, with_aug, balanced, pretrained, batch_128, topn]\n",
      "Index: []\n",
      "=====================\n",
      "[Errno 2] No such file or directory: '/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/top-7/Feb25_01-20-42_p4-r66-b.g42cloud.net_classify_top-7_resnet18_RSPECT_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt'\n",
      "[Model Loading Error]\n",
      "/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/top-7/Feb25_01-20-42_p4-r66-b.g42cloud.net_classify_top-7_resnet18_RSPECT_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt\n",
      "resnet18\n",
      "[Errno 2] No such file or directory: '/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/raw/Feb25_16-52-57_p1-r02-a.g42cloud.net_classify_raw_efficientnetb4_kits_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt'\n",
      "[Model Loading Error]\n",
      "/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/raw/Feb25_16-52-57_p1-r02-a.g42cloud.net_classify_raw_efficientnetb4_kits_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt\n",
      "efficientnet_b4\n",
      "[Errno 2] No such file or directory: '/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/raw/Feb25_22-29-01_p3-r56-b.g42cloud.net_classify_raw_densenet121_ProstateMRI_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt'\n",
      "[Model Loading Error]\n",
      "/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/raw/Feb25_22-29-01_p3-r56-b.g42cloud.net_classify_raw_densenet121_ProstateMRI_batch_128_with_shuffle_with_aug_balanced/model_epoch_0.pt\n",
      "densenet121\n"
     ]
    }
   ],
   "source": [
    "from meta.embedding import ModelEmbeddings\n",
    "model_embed = ModelEmbeddings()\n",
    "_model_dict = model_embed.parse_and_embed()\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(_model_dict)\n",
    "model_dict = df.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_epoch', 'acc', 'f1', 'loss', 'model_path', 'dataset', 'model', 'with_aug', 'balanced', 'pretrained', 'batch_128', 'topn', 'f_emb'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>model_path</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>with_aug</th>\n",
       "      <th>balanced</th>\n",
       "      <th>pretrained</th>\n",
       "      <th>batch_128</th>\n",
       "      <th>topn</th>\n",
       "      <th>f_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>IHD_Brain</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.439231</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>IHD_Brain</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.507455</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.235808</td>\n",
       "      <td>0.549068</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>22</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.089775</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ImageCHD</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(2.0657), tensor(2.1143), tensor(1.8511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>100</td>\n",
       "      <td>0.932258</td>\n",
       "      <td>0.932258</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>Brain_MRI</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.4187), tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>44</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>MosMed</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>85</td>\n",
       "      <td>0.859747</td>\n",
       "      <td>0.530511</td>\n",
       "      <td>0.094970</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>kits</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>35</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.471072</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ProstateMRI</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_epoch       acc        f1      loss  \\\n",
       "0            46  0.826667  0.452632  0.278173   \n",
       "1            97  0.790000  0.790698  0.439231   \n",
       "2            11  0.776667  0.263736  0.507455   \n",
       "3            16  0.708333  0.235808  0.549068   \n",
       "4            95  0.950000  0.210526  0.150664   \n",
       "..          ...       ...       ...       ...   \n",
       "375          22  0.818750  0.188811  0.089775   \n",
       "376         100  0.932258  0.932258  0.013777   \n",
       "377          44  0.759375  0.702703  0.143112   \n",
       "378          85  0.859747  0.530511  0.094970   \n",
       "379          35  0.773438  0.594406  0.471072   \n",
       "\n",
       "                                            model_path      dataset  \\\n",
       "0    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    IHD_Brain   \n",
       "1    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    IHD_Brain   \n",
       "2    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "3    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "4    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "..                                                 ...          ...   \n",
       "375  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...     ImageCHD   \n",
       "376  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    Brain_MRI   \n",
       "377  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       MosMed   \n",
       "378  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...         kits   \n",
       "379  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...  ProstateMRI   \n",
       "\n",
       "            model  with_aug  balanced  pretrained  batch_128   topn  \\\n",
       "0        resnet18     False     False       False      False  top-2   \n",
       "1        resnet50      True      True       False       True  top-2   \n",
       "2        resnet18      True     False        True       True  top-2   \n",
       "3    mobilenet_v2      True     False       False       True  top-2   \n",
       "4        resnet50      True     False       False      False  top-2   \n",
       "..            ...       ...       ...         ...        ...    ...   \n",
       "375  mobilenet_v2      True     False       False      False    raw   \n",
       "376      resnet18      True      True        True       True    raw   \n",
       "377      resnet18      True     False       False      False    raw   \n",
       "378      resnet50      True      True       False       True    raw   \n",
       "379      resnet50      True     False       False       True    raw   \n",
       "\n",
       "                                                 f_emb  \n",
       "0    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "1    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "2    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "3    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "4    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "..                                                 ...  \n",
       "375  [tensor(2.0657), tensor(2.1143), tensor(1.8511...  \n",
       "376  [tensor(0.), tensor(0.), tensor(0.4187), tenso...  \n",
       "377  [tensor(0.), tensor(0.), tensor(0.), tensor(2....  \n",
       "378  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "379  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "\n",
       "[380 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_epoch 46\n",
      "acc 0.8266666666666667\n",
      "f1 0.45263157894736844\n",
      "loss 0.2781733729640643\n",
      "model_path /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/classification/CT/post_sanity/top-2/Feb21_22-35-57_p4-r66-a.g42cloud.net_classify_top-2_resnet18_IHD_Brain_with_shuffle_without_aug/model_epoch_46.pt\n",
      "dataset IHD_Brain\n",
      "model resnet18\n",
      "with_aug False\n",
      "balanced False\n",
      "pretrained False\n",
      "batch_128 False\n",
      "topn top-2\n",
      "f_emb tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for k, v in df.iloc[0].items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model_dict, '/nfs/projects/mbzuai/shikhar/datasets/ofa/our_mod_zoo.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_epoch', 'acc', 'f1', 'loss', 'model_path', 'dataset', 'model', 'with_aug', 'balanced', 'pretrained', 'batch_128', 'topn', 'f_emb'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['f_emb'][10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "for row in df['f_emb']:\n",
    "    clear_output(wait = False)\n",
    "    print(row.numpy().shape)\n",
    "    print(list(row.numpy()))\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>model_path</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>with_aug</th>\n",
       "      <th>balanced</th>\n",
       "      <th>topn</th>\n",
       "      <th>f_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>IHD_Brain</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.507455</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.235808</td>\n",
       "      <td>0.549068</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.451216</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>RSPECT</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>top-2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9</td>\n",
       "      <td>0.819531</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.442918</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ImageCHD</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(41.2831), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>42</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.780415</td>\n",
       "      <td>0.259087</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>CTPancreas</td>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.0308), tensor(-0.0279), tensor(-0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>22</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.089775</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ImageCHD</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(2.0657), tensor(2.1143), tensor(1.8511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>44</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>MosMed</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>35</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.471072</td>\n",
       "      <td>/nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...</td>\n",
       "      <td>ProstateMRI</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>raw</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_epoch       acc        f1      loss  \\\n",
       "0            46  0.826667  0.452632  0.278173   \n",
       "1            11  0.776667  0.263736  0.507455   \n",
       "2            16  0.708333  0.235808  0.549068   \n",
       "3            95  0.950000  0.210526  0.150664   \n",
       "4            18  0.813333  0.827692  0.451216   \n",
       "..          ...       ...       ...       ...   \n",
       "295           9  0.819531  0.094118  0.442918   \n",
       "296          42  0.855469  0.780415  0.259087   \n",
       "297          22  0.818750  0.188811  0.089775   \n",
       "298          44  0.759375  0.702703  0.143112   \n",
       "299          35  0.773438  0.594406  0.471072   \n",
       "\n",
       "                                            model_path      dataset  \\\n",
       "0    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...    IHD_Brain   \n",
       "1    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "2    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "3    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "4    /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       RSPECT   \n",
       "..                                                 ...          ...   \n",
       "295  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...     ImageCHD   \n",
       "296  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...   CTPancreas   \n",
       "297  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...     ImageCHD   \n",
       "298  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...       MosMed   \n",
       "299  /nfs/projects/mbzuai/BioMedIA/MICCIA_22/logs/c...  ProstateMRI   \n",
       "\n",
       "               model  with_aug  balanced   topn  \\\n",
       "0           resnet18     False     False  top-2   \n",
       "1           resnet18      True     False  top-2   \n",
       "2       mobilenet_v2      True     False  top-2   \n",
       "3           resnet50      True     False  top-2   \n",
       "4       mobilenet_v2      True      True  top-2   \n",
       "..               ...       ...       ...    ...   \n",
       "295         resnet50      True     False    raw   \n",
       "296  efficientnet_b4      True     False    raw   \n",
       "297     mobilenet_v2      True     False    raw   \n",
       "298         resnet18      True     False    raw   \n",
       "299         resnet50      True     False    raw   \n",
       "\n",
       "                                                 f_emb  \n",
       "0    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "1    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "2    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "3    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "4    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "..                                                 ...  \n",
       "295  [tensor(0.), tensor(0.), tensor(41.2831), tens...  \n",
       "296  [tensor(0.0308), tensor(-0.0279), tensor(-0.01...  \n",
       "297  [tensor(2.0657), tensor(2.1143), tensor(1.8511...  \n",
       "298  [tensor(0.), tensor(0.), tensor(0.), tensor(2....  \n",
       "299  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import clear_output\n",
    "for row in df['x_query_train'][0]:\n",
    "    print(row.numpy().shape)\n",
    "    print(list(row.numpy()))\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38470bdf3e966986ca85f0825073bcf86ddf5dbb9002a7f4b160e6f6a6aff5a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ofa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
